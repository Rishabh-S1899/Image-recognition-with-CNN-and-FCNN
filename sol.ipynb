{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path,label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    count=0\n",
    "    file_list = os.listdir(folder_path)\n",
    "    for filename in file_list:\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        # print(count)\n",
    "        img = cv2.imread(img_path)\n",
    "        # print('NO')\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            count+=1\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name=['Class_0','Class_1','Class_2']\n",
    "images_new=['a','b','c']\n",
    "labels_new=['a','b','c']\n",
    "for x in range(len(folder_name)):\n",
    "    # print(x)\n",
    "    folder_path = rf'C:\\Users\\risha\\Desktop\\IC272\\Assignments\\Assignment-5\\cifar-3class-data\\train\\{folder_name[x]}'\n",
    "    images, labels = load_images_from_folder(folder_path,folder_name[x])\n",
    "    images_new[x]=images\n",
    "    labels_new[x]=labels\n",
    "images_new=np.array(images_new)\n",
    "# images_new[0]\n",
    "X=np.concatenate((images_new[0],images_new[1],images_new[2]),axis=0)\n",
    "y=np.concatenate((labels_new[0],labels_new[1],labels_new[2]),axis=0)\n",
    "\n",
    "# y.shape\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name=['Class_0','Class_1','Class_2']\n",
    "images_new_test=['a','b','c']\n",
    "labels_new_test=['a','b','c']\n",
    "for x in range(len(folder_name)):\n",
    "    # print(x)\n",
    "    folder_path = rf'C:\\Users\\risha\\Desktop\\IC272\\Assignments\\Assignment-5\\cifar-3class-data\\test\\{folder_name[x]}'\n",
    "    images, labels = load_images_from_folder(folder_path,folder_name[x])\n",
    "    images_new_test[x]=images\n",
    "    labels_new_test[x]=labels\n",
    "images_new_test=np.array(images_new_test)\n",
    "\n",
    "X_t=np.concatenate((images_new_test[0],images_new_test[1],images_new_test[2]),axis=0)\n",
    "y_t=np.concatenate((labels_new_test[0],labels_new_test[1],labels_new_test[2]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape\n",
    "# y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X[0])\n",
    "plt.subplot(222)\n",
    "plt.imshow(X[1])\n",
    "plt.subplot(223)\n",
    "plt.imshow(X[2])\n",
    "plt.subplot(224)\n",
    "plt.imshow(X[3])\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.1,random_state=True,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 32, 32, 3)\n",
      "(1350,)\n",
      "(150, 32, 32, 3)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 98, 126, 164],\n",
       "         [ 97, 125, 159],\n",
       "         [103, 132, 162],\n",
       "         ...,\n",
       "         [ 99, 126, 157],\n",
       "         [106, 133, 162],\n",
       "         [103, 130, 157]],\n",
       "\n",
       "        [[100, 128, 167],\n",
       "         [ 98, 126, 162],\n",
       "         [103, 132, 167],\n",
       "         ...,\n",
       "         [ 94, 121, 153],\n",
       "         [102, 129, 158],\n",
       "         [100, 127, 154]],\n",
       "\n",
       "        [[101, 129, 169],\n",
       "         [ 98, 126, 164],\n",
       "         [109, 137, 175],\n",
       "         ...,\n",
       "         [ 94, 121, 153],\n",
       "         [104, 131, 160],\n",
       "         [ 98, 126, 153]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 40,  57,  84],\n",
       "         [ 78, 102, 137],\n",
       "         [ 79, 114, 172],\n",
       "         ...,\n",
       "         [ 41,  51,  83],\n",
       "         [ 42,  60,  98],\n",
       "         [ 83, 109, 162]],\n",
       "\n",
       "        [[ 29,  46,  68],\n",
       "         [ 57,  79, 113],\n",
       "         [ 71, 104, 155],\n",
       "         ...,\n",
       "         [ 51,  69, 109],\n",
       "         [ 56,  81, 132],\n",
       "         [127, 161, 206]],\n",
       "\n",
       "        [[ 32,  44,  65],\n",
       "         [ 54,  71, 100],\n",
       "         [ 75, 102, 142],\n",
       "         ...,\n",
       "         [ 54,  73, 115],\n",
       "         [ 82, 108, 163],\n",
       "         [153, 188, 230]]],\n",
       "\n",
       "\n",
       "       [[[ 49,  50,  44],\n",
       "         [ 52,  53,  47],\n",
       "         [ 62,  58,  48],\n",
       "         ...,\n",
       "         [ 73,  71,  64],\n",
       "         [ 66,  66,  61],\n",
       "         [ 52,  53,  50]],\n",
       "\n",
       "        [[ 51,  52,  46],\n",
       "         [ 54,  56,  48],\n",
       "         [ 57,  58,  48],\n",
       "         ...,\n",
       "         [ 78,  76,  69],\n",
       "         [ 73,  73,  68],\n",
       "         [ 56,  57,  53]],\n",
       "\n",
       "        [[ 54,  55,  47],\n",
       "         [ 57,  59,  50],\n",
       "         [ 58,  60,  51],\n",
       "         ...,\n",
       "         [ 84,  81,  75],\n",
       "         [ 80,  80,  75],\n",
       "         [ 62,  62,  59]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[104,  89,  81],\n",
       "         [164, 154, 134],\n",
       "         [ 62,  58,  50],\n",
       "         ...,\n",
       "         [ 55,  48,  34],\n",
       "         [ 73,  55,  37],\n",
       "         [ 86,  55,  34]],\n",
       "\n",
       "        [[ 96,  81,  74],\n",
       "         [192, 176, 155],\n",
       "         [141, 132, 116],\n",
       "         ...,\n",
       "         [ 60,  50,  36],\n",
       "         [ 70,  56,  38],\n",
       "         [ 76,  58,  36]],\n",
       "\n",
       "        [[ 88,  79,  73],\n",
       "         [189, 174, 156],\n",
       "         [213, 200, 176],\n",
       "         ...,\n",
       "         [ 65,  55,  41],\n",
       "         [ 66,  58,  44],\n",
       "         [ 67,  60,  43]]],\n",
       "\n",
       "\n",
       "       [[[147, 164, 190],\n",
       "         [145, 162, 188],\n",
       "         [145, 162, 188],\n",
       "         ...,\n",
       "         [145, 162, 188],\n",
       "         [145, 162, 188],\n",
       "         [145, 162, 188]],\n",
       "\n",
       "        [[147, 165, 191],\n",
       "         [145, 162, 188],\n",
       "         [146, 163, 189],\n",
       "         ...,\n",
       "         [146, 163, 189],\n",
       "         [146, 163, 189],\n",
       "         [146, 163, 189]],\n",
       "\n",
       "        [[148, 165, 191],\n",
       "         [146, 163, 189],\n",
       "         [147, 164, 190],\n",
       "         ...,\n",
       "         [146, 163, 189],\n",
       "         [146, 163, 189],\n",
       "         [146, 163, 189]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[152, 168, 190],\n",
       "         [150, 165, 187],\n",
       "         [150, 165, 187],\n",
       "         ...,\n",
       "         [150, 165, 187],\n",
       "         [150, 165, 187],\n",
       "         [150, 165, 187]],\n",
       "\n",
       "        [[152, 168, 189],\n",
       "         [150, 165, 186],\n",
       "         [150, 165, 186],\n",
       "         ...,\n",
       "         [150, 165, 186],\n",
       "         [150, 165, 186],\n",
       "         [150, 165, 186]],\n",
       "\n",
       "        [[152, 167, 188],\n",
       "         [149, 164, 185],\n",
       "         [149, 164, 185],\n",
       "         ...,\n",
       "         [149, 164, 185],\n",
       "         [149, 164, 185],\n",
       "         [149, 164, 185]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[100, 101,  65],\n",
       "         [100, 101,  66],\n",
       "         [101, 102,  66],\n",
       "         ...,\n",
       "         [ 66,  78,  54],\n",
       "         [ 67,  79,  55],\n",
       "         [ 67,  79,  55]],\n",
       "\n",
       "        [[101, 100,  67],\n",
       "         [100,  99,  66],\n",
       "         [101, 101,  67],\n",
       "         ...,\n",
       "         [ 68,  80,  54],\n",
       "         [ 69,  82,  56],\n",
       "         [ 69,  82,  56]],\n",
       "\n",
       "        [[ 94,  90,  60],\n",
       "         [ 88,  84,  54],\n",
       "         [ 97,  93,  63],\n",
       "         ...,\n",
       "         [ 71,  83,  55],\n",
       "         [ 71,  85,  57],\n",
       "         [ 72,  85,  57]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[122, 108,  68],\n",
       "         [128, 113,  73],\n",
       "         [127, 117,  76],\n",
       "         ...,\n",
       "         [113, 109,  77],\n",
       "         [114, 109,  78],\n",
       "         [113, 109,  77]],\n",
       "\n",
       "        [[143, 125,  85],\n",
       "         [142, 121,  83],\n",
       "         [128, 112,  73],\n",
       "         ...,\n",
       "         [107, 108,  70],\n",
       "         [106, 107,  69],\n",
       "         [106, 107,  69]],\n",
       "\n",
       "        [[118, 103,  67],\n",
       "         [ 97,  81,  46],\n",
       "         [ 86,  70,  40],\n",
       "         ...,\n",
       "         [108, 107,  68],\n",
       "         [107, 107,  68],\n",
       "         [108, 107,  69]]],\n",
       "\n",
       "\n",
       "       [[[170, 195, 215],\n",
       "         [172, 197, 217],\n",
       "         [174, 199, 219],\n",
       "         ...,\n",
       "         [199, 221, 237],\n",
       "         [198, 221, 237],\n",
       "         [199, 222, 238]],\n",
       "\n",
       "        [[174, 199, 219],\n",
       "         [176, 201, 221],\n",
       "         [178, 202, 222],\n",
       "         ...,\n",
       "         [202, 224, 238],\n",
       "         [202, 224, 238],\n",
       "         [203, 225, 239]],\n",
       "\n",
       "        [[178, 202, 220],\n",
       "         [180, 204, 222],\n",
       "         [182, 205, 223],\n",
       "         ...,\n",
       "         [204, 226, 239],\n",
       "         [204, 226, 239],\n",
       "         [205, 227, 240]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[225, 206, 200],\n",
       "         [228, 209, 203],\n",
       "         [227, 208, 202],\n",
       "         ...,\n",
       "         [  0,  28,  31],\n",
       "         [ 10,  29,  34],\n",
       "         [ 82,  88,  95]],\n",
       "\n",
       "        [[223, 204, 198],\n",
       "         [226, 207, 201],\n",
       "         [227, 208, 202],\n",
       "         ...,\n",
       "         [ 36,  46,  42],\n",
       "         [130, 132, 128],\n",
       "         [214, 206, 202]],\n",
       "\n",
       "        [[225, 206, 200],\n",
       "         [228, 209, 203],\n",
       "         [229, 210, 204],\n",
       "         ...,\n",
       "         [188, 170, 163],\n",
       "         [227, 211, 200],\n",
       "         [226, 211, 196]]],\n",
       "\n",
       "\n",
       "       [[[ 29,  49,  76],\n",
       "         [ 35,  53,  82],\n",
       "         [ 32,  50,  80],\n",
       "         ...,\n",
       "         [ 23,  40,  63],\n",
       "         [ 23,  37,  54],\n",
       "         [ 22,  33,  47]],\n",
       "\n",
       "        [[ 27,  45,  74],\n",
       "         [ 28,  46,  74],\n",
       "         [ 29,  46,  74],\n",
       "         ...,\n",
       "         [ 25,  38,  58],\n",
       "         [ 24,  37,  54],\n",
       "         [ 25,  38,  56]],\n",
       "\n",
       "        [[ 25,  43,  71],\n",
       "         [ 25,  42,  68],\n",
       "         [ 25,  40,  64],\n",
       "         ...,\n",
       "         [ 29,  44,  65],\n",
       "         [ 28,  43,  69],\n",
       "         [ 29,  45,  70]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 20,  29,  44],\n",
       "         [ 21,  31,  44],\n",
       "         [ 21,  30,  44],\n",
       "         ...,\n",
       "         [  5,   9,  13],\n",
       "         [  4,   9,  13],\n",
       "         [  4,   9,  11]],\n",
       "\n",
       "        [[ 25,  38,  51],\n",
       "         [ 23,  34,  47],\n",
       "         [ 24,  32,  47],\n",
       "         ...,\n",
       "         [  4,  12,  20],\n",
       "         [  3,  10,  17],\n",
       "         [  4,   8,  11]],\n",
       "\n",
       "        [[ 39,  53,  61],\n",
       "         [ 26,  40,  50],\n",
       "         [ 25,  37,  51],\n",
       "         ...,\n",
       "         [  9,  18,  28],\n",
       "         [  9,  20,  34],\n",
       "         [  8,  17,  31]]]], dtype=uint8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "3072\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "def flatten_rgb_images(images):\n",
    "    flattened_vectors = []\n",
    "    for image in images:\n",
    "        flattened_vector = []\n",
    "        for row in image:\n",
    "            for pixel in row:\n",
    "                flattened_vector.extend(pixel)\n",
    "        flattened_vectors.append(flattened_vector)\n",
    "    return flattened_vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    images_array = np.array(images)\n",
    "\n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    normalized_images = images_array / 255.0\n",
    "\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final=flatten_rgb_images(X_train)\n",
    "X_train_final=normalize_images(X_train_final)\n",
    "X_val_final=flatten_rgb_images(X_val)\n",
    "X_val_final=normalize_images(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "def one_hot_encoder(arr):\n",
    "    class_indices = np.unique(arr, return_inverse=True)[1]\n",
    "    arr_one_hot = to_categorical(class_indices, num_classes=len(np.unique(arr)))\n",
    "    return arr_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot=one_hot_encoder(y_train)\n",
    "y_val_one_hot=one_hot_encoder(y_val)\n",
    "\n",
    "y_val_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final=flatten_rgb_images(X_t)\n",
    "X_test_final=normalize_images(X_test_final)\n",
    "y_test_final=one_hot_encoder(y_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=500\n",
    "batches=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_81 (Dense)            (None, 256)               786688    \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 828035 (3.16 MB)\n",
      "Trainable params: 828035 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(layers.InputLayer(input_shape=(3072,)))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.0772 - accuracy: 0.3120\n",
      "Epoch 1: val_accuracy improved from -inf to 0.38667, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 1s 52ms/step - loss: 1.9555 - accuracy: 0.3193 - val_loss: 1.3449 - val_accuracy: 0.3867\n",
      "Epoch 2/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.2717 - accuracy: 0.3420\n",
      "Epoch 2: val_accuracy did not improve from 0.38667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.2217 - accuracy: 0.3548 - val_loss: 1.1232 - val_accuracy: 0.3200\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1093 - accuracy: 0.3560\n",
      "Epoch 3: val_accuracy improved from 0.38667 to 0.40667, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.0824 - accuracy: 0.3941 - val_loss: 1.1380 - val_accuracy: 0.4067\n",
      "Epoch 4/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.0065 - accuracy: 0.5020\n",
      "Epoch 4: val_accuracy improved from 0.40667 to 0.66667, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.0140 - accuracy: 0.5022 - val_loss: 0.9285 - val_accuracy: 0.6667\n",
      "Epoch 5/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.9583 - accuracy: 0.5390\n",
      "Epoch 5: val_accuracy did not improve from 0.66667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9428 - accuracy: 0.5541 - val_loss: 0.9267 - val_accuracy: 0.5667\n",
      "Epoch 6/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.9190 - accuracy: 0.5930\n",
      "Epoch 6: val_accuracy did not improve from 0.66667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9242 - accuracy: 0.5793 - val_loss: 0.9200 - val_accuracy: 0.5667\n",
      "Epoch 7/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.8694 - accuracy: 0.6330\n",
      "Epoch 7: val_accuracy did not improve from 0.66667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8676 - accuracy: 0.6385 - val_loss: 0.9033 - val_accuracy: 0.5733\n",
      "Epoch 8/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.8294 - accuracy: 0.6510\n",
      "Epoch 8: val_accuracy did not improve from 0.66667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8281 - accuracy: 0.6496 - val_loss: 0.8746 - val_accuracy: 0.6333\n",
      "Epoch 9/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.8232 - accuracy: 0.6520\n",
      "Epoch 9: val_accuracy improved from 0.66667 to 0.69333, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.8124 - accuracy: 0.6541 - val_loss: 0.8384 - val_accuracy: 0.6933\n",
      "Epoch 10/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.7885 - accuracy: 0.6810\n",
      "Epoch 10: val_accuracy improved from 0.69333 to 0.71333, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7948 - accuracy: 0.6785 - val_loss: 0.7868 - val_accuracy: 0.7133\n",
      "Epoch 11/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.7723 - accuracy: 0.6810\n",
      "Epoch 11: val_accuracy did not improve from 0.71333\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.7673 - accuracy: 0.6837 - val_loss: 0.7603 - val_accuracy: 0.7000\n",
      "Epoch 12/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.7527 - accuracy: 0.6890\n",
      "Epoch 12: val_accuracy improved from 0.71333 to 0.72000, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.7621 - accuracy: 0.6807 - val_loss: 0.7497 - val_accuracy: 0.7200\n",
      "Epoch 13/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.7739 - accuracy: 0.6550\n",
      "Epoch 13: val_accuracy improved from 0.72000 to 0.74000, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.7704 - accuracy: 0.6607 - val_loss: 0.7440 - val_accuracy: 0.7400\n",
      "Epoch 14/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.7419 - accuracy: 0.6800\n",
      "Epoch 14: val_accuracy did not improve from 0.74000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.7390 - accuracy: 0.6837 - val_loss: 0.7428 - val_accuracy: 0.7400\n",
      "Epoch 15/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.7034 - accuracy: 0.7270\n",
      "Epoch 15: val_accuracy did not improve from 0.74000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6981 - accuracy: 0.7244 - val_loss: 0.7309 - val_accuracy: 0.7200\n",
      "Epoch 16/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6743 - accuracy: 0.7250\n",
      "Epoch 16: val_accuracy did not improve from 0.74000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6807 - accuracy: 0.7259 - val_loss: 0.7811 - val_accuracy: 0.7067\n",
      "Epoch 17/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6858 - accuracy: 0.7180\n",
      "Epoch 17: val_accuracy did not improve from 0.74000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6829 - accuracy: 0.7170 - val_loss: 0.7038 - val_accuracy: 0.7267\n",
      "Epoch 18/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6539 - accuracy: 0.7370\n",
      "Epoch 18: val_accuracy did not improve from 0.74000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6603 - accuracy: 0.7393 - val_loss: 0.7255 - val_accuracy: 0.6867\n",
      "Epoch 19/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6634 - accuracy: 0.7360\n",
      "Epoch 19: val_accuracy improved from 0.74000 to 0.74667, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6589 - accuracy: 0.7356 - val_loss: 0.7074 - val_accuracy: 0.7467\n",
      "Epoch 20/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6344 - accuracy: 0.7480\n",
      "Epoch 20: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6357 - accuracy: 0.7526 - val_loss: 0.6970 - val_accuracy: 0.7000\n",
      "Epoch 21/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6273 - accuracy: 0.7500\n",
      "Epoch 21: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6623 - accuracy: 0.7289 - val_loss: 0.8173 - val_accuracy: 0.6467\n",
      "Epoch 22/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6648 - accuracy: 0.7230\n",
      "Epoch 22: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6544 - accuracy: 0.7326 - val_loss: 0.7474 - val_accuracy: 0.7467\n",
      "Epoch 23/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6227 - accuracy: 0.7450\n",
      "Epoch 23: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6194 - accuracy: 0.7496 - val_loss: 0.6953 - val_accuracy: 0.7200\n",
      "Epoch 24/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.6081 - accuracy: 0.7650\n",
      "Epoch 24: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5994 - accuracy: 0.7704 - val_loss: 0.6682 - val_accuracy: 0.7200\n",
      "Epoch 25/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.6240 - accuracy: 0.7490\n",
      "Epoch 25: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6111 - accuracy: 0.7519 - val_loss: 0.7128 - val_accuracy: 0.6867\n",
      "Epoch 26/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5679 - accuracy: 0.7900\n",
      "Epoch 26: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5670 - accuracy: 0.7844 - val_loss: 0.7069 - val_accuracy: 0.7200\n",
      "Epoch 27/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5493 - accuracy: 0.7810\n",
      "Epoch 27: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5517 - accuracy: 0.7778 - val_loss: 0.7121 - val_accuracy: 0.7133\n",
      "Epoch 28/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5395 - accuracy: 0.7870\n",
      "Epoch 28: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5501 - accuracy: 0.7830 - val_loss: 0.7616 - val_accuracy: 0.6933\n",
      "Epoch 29/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5315 - accuracy: 0.7860\n",
      "Epoch 29: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5500 - accuracy: 0.7748 - val_loss: 0.7033 - val_accuracy: 0.7067\n",
      "Epoch 30/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5297 - accuracy: 0.7870\n",
      "Epoch 30: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5201 - accuracy: 0.7896 - val_loss: 0.7344 - val_accuracy: 0.6733\n",
      "Epoch 31/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5462 - accuracy: 0.7710\n",
      "Epoch 31: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5367 - accuracy: 0.7770 - val_loss: 0.7070 - val_accuracy: 0.6867\n",
      "Epoch 32/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4995 - accuracy: 0.8110\n",
      "Epoch 32: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.5006 - accuracy: 0.8096 - val_loss: 0.7157 - val_accuracy: 0.7200\n",
      "Epoch 33/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4858 - accuracy: 0.8110\n",
      "Epoch 33: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4896 - accuracy: 0.8104 - val_loss: 0.8521 - val_accuracy: 0.6400\n",
      "Epoch 34/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5232 - accuracy: 0.7750\n",
      "Epoch 34: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5356 - accuracy: 0.7726 - val_loss: 0.7029 - val_accuracy: 0.7467\n",
      "Epoch 35/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4970 - accuracy: 0.8110\n",
      "Epoch 35: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4994 - accuracy: 0.8037 - val_loss: 0.8328 - val_accuracy: 0.6533\n",
      "Epoch 36/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5428 - accuracy: 0.7810\n",
      "Epoch 36: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5351 - accuracy: 0.7852 - val_loss: 0.7006 - val_accuracy: 0.7200\n",
      "Epoch 37/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4954 - accuracy: 0.7990\n",
      "Epoch 37: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4796 - accuracy: 0.8044 - val_loss: 0.7005 - val_accuracy: 0.7267\n",
      "Epoch 38/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4602 - accuracy: 0.8170\n",
      "Epoch 38: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4514 - accuracy: 0.8274 - val_loss: 0.6934 - val_accuracy: 0.7133\n",
      "Epoch 39/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4205 - accuracy: 0.8420\n",
      "Epoch 39: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4335 - accuracy: 0.8304 - val_loss: 0.6714 - val_accuracy: 0.7267\n",
      "Epoch 40/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4266 - accuracy: 0.8350\n",
      "Epoch 40: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4334 - accuracy: 0.8326 - val_loss: 0.7543 - val_accuracy: 0.6800\n",
      "Epoch 41/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5291 - accuracy: 0.7690\n",
      "Epoch 41: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5337 - accuracy: 0.7748 - val_loss: 0.7569 - val_accuracy: 0.6600\n",
      "Epoch 42/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.5029 - accuracy: 0.7990\n",
      "Epoch 42: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4838 - accuracy: 0.8081 - val_loss: 0.6657 - val_accuracy: 0.6933\n",
      "Epoch 43/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4602 - accuracy: 0.8160\n",
      "Epoch 43: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4527 - accuracy: 0.8163 - val_loss: 0.7407 - val_accuracy: 0.6867\n",
      "Epoch 44/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4445 - accuracy: 0.8170\n",
      "Epoch 44: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4436 - accuracy: 0.8215 - val_loss: 0.6611 - val_accuracy: 0.7267\n",
      "Epoch 45/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3930 - accuracy: 0.8540\n",
      "Epoch 45: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3990 - accuracy: 0.8533 - val_loss: 0.6840 - val_accuracy: 0.7200\n",
      "Epoch 46/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3815 - accuracy: 0.8490\n",
      "Epoch 46: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3816 - accuracy: 0.8489 - val_loss: 0.7382 - val_accuracy: 0.6867\n",
      "Epoch 47/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3581 - accuracy: 0.8710\n",
      "Epoch 47: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3637 - accuracy: 0.8659 - val_loss: 0.6973 - val_accuracy: 0.7067\n",
      "Epoch 48/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.3423 - accuracy: 0.8687\n",
      "Epoch 48: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3584 - accuracy: 0.8600 - val_loss: 0.7787 - val_accuracy: 0.6600\n",
      "Epoch 49/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.4015 - accuracy: 0.8263\n",
      "Epoch 49: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3792 - accuracy: 0.8430 - val_loss: 0.7403 - val_accuracy: 0.7133\n",
      "Epoch 50/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3612 - accuracy: 0.8580\n",
      "Epoch 50: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3504 - accuracy: 0.8593 - val_loss: 0.7246 - val_accuracy: 0.6933\n",
      "Epoch 51/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3144 - accuracy: 0.8820\n",
      "Epoch 51: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3367 - accuracy: 0.8667 - val_loss: 0.7754 - val_accuracy: 0.7067\n",
      "Epoch 52/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3161 - accuracy: 0.8780\n",
      "Epoch 52: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3261 - accuracy: 0.8704 - val_loss: 0.7547 - val_accuracy: 0.6867\n",
      "Epoch 53/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3556 - accuracy: 0.8590\n",
      "Epoch 53: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3487 - accuracy: 0.8659 - val_loss: 0.7269 - val_accuracy: 0.7133\n",
      "Epoch 54/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3557 - accuracy: 0.8600\n",
      "Epoch 54: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3563 - accuracy: 0.8563 - val_loss: 0.7273 - val_accuracy: 0.7200\n",
      "Epoch 55/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3937 - accuracy: 0.8240\n",
      "Epoch 55: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3751 - accuracy: 0.8444 - val_loss: 0.7844 - val_accuracy: 0.7067\n",
      "Epoch 56/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3426 - accuracy: 0.8600\n",
      "Epoch 56: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3397 - accuracy: 0.8659 - val_loss: 0.8032 - val_accuracy: 0.7267\n",
      "Epoch 57/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3258 - accuracy: 0.8640\n",
      "Epoch 57: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3188 - accuracy: 0.8689 - val_loss: 0.6692 - val_accuracy: 0.7333\n",
      "Epoch 58/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.3098 - accuracy: 0.8790\n",
      "Epoch 58: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3005 - accuracy: 0.8837 - val_loss: 0.7902 - val_accuracy: 0.7067\n",
      "Epoch 59/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2726 - accuracy: 0.8980\n",
      "Epoch 59: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2720 - accuracy: 0.9000 - val_loss: 0.7330 - val_accuracy: 0.7267\n",
      "Epoch 60/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2657 - accuracy: 0.8930\n",
      "Epoch 60: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2602 - accuracy: 0.8978 - val_loss: 0.7730 - val_accuracy: 0.7067\n",
      "Epoch 61/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2743 - accuracy: 0.9000\n",
      "Epoch 61: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2885 - accuracy: 0.8896 - val_loss: 0.7193 - val_accuracy: 0.7267\n",
      "Epoch 62/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2715 - accuracy: 0.8920\n",
      "Epoch 62: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2714 - accuracy: 0.8867 - val_loss: 0.7419 - val_accuracy: 0.7333\n",
      "Epoch 63/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2778 - accuracy: 0.8900\n",
      "Epoch 63: val_accuracy did not improve from 0.74667\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2804 - accuracy: 0.8919 - val_loss: 0.9019 - val_accuracy: 0.7067\n",
      "Epoch 64/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2780 - accuracy: 0.8850\n",
      "Epoch 64: val_accuracy improved from 0.74667 to 0.75333, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2667 - accuracy: 0.8896 - val_loss: 0.7105 - val_accuracy: 0.7533\n",
      "Epoch 65/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2385 - accuracy: 0.9060\n",
      "Epoch 65: val_accuracy did not improve from 0.75333\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2296 - accuracy: 0.9096 - val_loss: 0.8034 - val_accuracy: 0.7133\n",
      "Epoch 66/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2516 - accuracy: 0.9130\n",
      "Epoch 66: val_accuracy did not improve from 0.75333\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2760 - accuracy: 0.9022 - val_loss: 0.8090 - val_accuracy: 0.7267\n",
      "Epoch 67/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2252 - accuracy: 0.9200\n",
      "Epoch 67: val_accuracy did not improve from 0.75333\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2338 - accuracy: 0.9141 - val_loss: 0.8325 - val_accuracy: 0.7133\n",
      "Epoch 68/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2217 - accuracy: 0.9230\n",
      "Epoch 68: val_accuracy did not improve from 0.75333\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2231 - accuracy: 0.9141 - val_loss: 0.7511 - val_accuracy: 0.7200\n",
      "Epoch 69/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2152 - accuracy: 0.9190\n",
      "Epoch 69: val_accuracy did not improve from 0.75333\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2140 - accuracy: 0.9200 - val_loss: 0.7375 - val_accuracy: 0.7467\n",
      "Epoch 70/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1810 - accuracy: 0.9380\n",
      "Epoch 70: val_accuracy improved from 0.75333 to 0.76000, saving model to FCCN_best_model.h5\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.1751 - accuracy: 0.9378 - val_loss: 0.7628 - val_accuracy: 0.7600\n",
      "Epoch 71/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1720 - accuracy: 0.9350\n",
      "Epoch 71: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1735 - accuracy: 0.9348 - val_loss: 0.7429 - val_accuracy: 0.7400\n",
      "Epoch 72/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2023 - accuracy: 0.9270\n",
      "Epoch 72: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2162 - accuracy: 0.9170 - val_loss: 0.8353 - val_accuracy: 0.7067\n",
      "Epoch 73/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2119 - accuracy: 0.9200\n",
      "Epoch 73: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2022 - accuracy: 0.9274 - val_loss: 0.6887 - val_accuracy: 0.6867\n",
      "Epoch 74/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1679 - accuracy: 0.9360\n",
      "Epoch 74: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1636 - accuracy: 0.9385 - val_loss: 0.8252 - val_accuracy: 0.7600\n",
      "Epoch 75/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1577 - accuracy: 0.9510\n",
      "Epoch 75: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1538 - accuracy: 0.9526 - val_loss: 0.8442 - val_accuracy: 0.7333\n",
      "Epoch 76/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1450 - accuracy: 0.9500\n",
      "Epoch 76: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1671 - accuracy: 0.9415 - val_loss: 0.9650 - val_accuracy: 0.7267\n",
      "Epoch 77/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1916 - accuracy: 0.9200\n",
      "Epoch 77: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1816 - accuracy: 0.9281 - val_loss: 0.7848 - val_accuracy: 0.6867\n",
      "Epoch 78/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1566 - accuracy: 0.9520\n",
      "Epoch 78: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1634 - accuracy: 0.9481 - val_loss: 0.8734 - val_accuracy: 0.7400\n",
      "Epoch 79/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1554 - accuracy: 0.9400\n",
      "Epoch 79: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1498 - accuracy: 0.9437 - val_loss: 0.8446 - val_accuracy: 0.7067\n",
      "Epoch 80/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1358 - accuracy: 0.9590\n",
      "Epoch 80: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1369 - accuracy: 0.9556 - val_loss: 0.9531 - val_accuracy: 0.7267\n",
      "Epoch 81/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1598 - accuracy: 0.9390\n",
      "Epoch 81: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1585 - accuracy: 0.9422 - val_loss: 0.9142 - val_accuracy: 0.7333\n",
      "Epoch 82/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1348 - accuracy: 0.9540\n",
      "Epoch 82: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1488 - accuracy: 0.9459 - val_loss: 0.8211 - val_accuracy: 0.7333\n",
      "Epoch 83/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2080 - accuracy: 0.9130\n",
      "Epoch 83: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2059 - accuracy: 0.9148 - val_loss: 0.8139 - val_accuracy: 0.7200\n",
      "Epoch 84/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2093 - accuracy: 0.9120\n",
      "Epoch 84: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1920 - accuracy: 0.9193 - val_loss: 0.9395 - val_accuracy: 0.6933\n",
      "Epoch 85/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2148 - accuracy: 0.9190\n",
      "Epoch 85: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.1999 - accuracy: 0.9237 - val_loss: 0.9304 - val_accuracy: 0.7333\n",
      "Epoch 86/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1367 - accuracy: 0.9530\n",
      "Epoch 86: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1459 - accuracy: 0.9474 - val_loss: 0.8083 - val_accuracy: 0.7067\n",
      "Epoch 87/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1377 - accuracy: 0.9570\n",
      "Epoch 87: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1370 - accuracy: 0.9548 - val_loss: 0.8498 - val_accuracy: 0.7533\n",
      "Epoch 88/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0983 - accuracy: 0.9630\n",
      "Epoch 88: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1000 - accuracy: 0.9644 - val_loss: 0.7976 - val_accuracy: 0.7467\n",
      "Epoch 89/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1170 - accuracy: 0.9630\n",
      "Epoch 89: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1119 - accuracy: 0.9659 - val_loss: 0.7317 - val_accuracy: 0.7400\n",
      "Epoch 90/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1049 - accuracy: 0.9650\n",
      "Epoch 90: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0996 - accuracy: 0.9652 - val_loss: 0.9281 - val_accuracy: 0.7467\n",
      "Epoch 91/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0977 - accuracy: 0.9710\n",
      "Epoch 91: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0970 - accuracy: 0.9689 - val_loss: 1.1013 - val_accuracy: 0.6933\n",
      "Epoch 92/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1688 - accuracy: 0.9360\n",
      "Epoch 92: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1745 - accuracy: 0.9326 - val_loss: 0.7845 - val_accuracy: 0.7133\n",
      "Epoch 93/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1179 - accuracy: 0.9560\n",
      "Epoch 93: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1147 - accuracy: 0.9593 - val_loss: 0.8941 - val_accuracy: 0.7000\n",
      "Epoch 94/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1002 - accuracy: 0.9760\n",
      "Epoch 94: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0927 - accuracy: 0.9756 - val_loss: 0.8371 - val_accuracy: 0.7400\n",
      "Epoch 95/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1007 - accuracy: 0.9690\n",
      "Epoch 95: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1018 - accuracy: 0.9674 - val_loss: 0.9619 - val_accuracy: 0.6933\n",
      "Epoch 96/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1037 - accuracy: 0.9650\n",
      "Epoch 96: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0966 - accuracy: 0.9652 - val_loss: 0.9399 - val_accuracy: 0.7467\n",
      "Epoch 97/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1321 - accuracy: 0.9490\n",
      "Epoch 97: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1268 - accuracy: 0.9533 - val_loss: 0.9446 - val_accuracy: 0.7333\n",
      "Epoch 98/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1737 - accuracy: 0.9320\n",
      "Epoch 98: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1619 - accuracy: 0.9370 - val_loss: 0.7693 - val_accuracy: 0.7067\n",
      "Epoch 99/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1187 - accuracy: 0.9560\n",
      "Epoch 99: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1304 - accuracy: 0.9489 - val_loss: 0.9441 - val_accuracy: 0.7467\n",
      "Epoch 100/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1000 - accuracy: 0.9650\n",
      "Epoch 100: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0968 - accuracy: 0.9689 - val_loss: 0.9251 - val_accuracy: 0.7200\n",
      "Epoch 101/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0895 - accuracy: 0.9690\n",
      "Epoch 101: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0800 - accuracy: 0.9726 - val_loss: 0.9453 - val_accuracy: 0.7533\n",
      "Epoch 102/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0789 - accuracy: 0.9740\n",
      "Epoch 102: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0784 - accuracy: 0.9748 - val_loss: 0.9274 - val_accuracy: 0.7000\n",
      "Epoch 103/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0700 - accuracy: 0.9770\n",
      "Epoch 103: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.9722 - val_accuracy: 0.7467\n",
      "Epoch 104/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0537 - accuracy: 0.9890\n",
      "Epoch 104: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0536 - accuracy: 0.9881 - val_loss: 0.8950 - val_accuracy: 0.7400\n",
      "Epoch 105/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0563 - accuracy: 0.9840\n",
      "Epoch 105: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0553 - accuracy: 0.9859 - val_loss: 0.9488 - val_accuracy: 0.7133\n",
      "Epoch 106/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0583 - accuracy: 0.9790\n",
      "Epoch 106: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.9676 - val_accuracy: 0.7533\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9874\n",
      "Epoch 107: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0515 - accuracy: 0.9874 - val_loss: 0.9401 - val_accuracy: 0.7533\n",
      "Epoch 108/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0465 - accuracy: 0.9860\n",
      "Epoch 108: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0517 - accuracy: 0.9822 - val_loss: 1.0993 - val_accuracy: 0.7467\n",
      "Epoch 109/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0731 - accuracy: 0.9720\n",
      "Epoch 109: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0675 - accuracy: 0.9756 - val_loss: 1.1480 - val_accuracy: 0.7267\n",
      "Epoch 110/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1252 - accuracy: 0.9540\n",
      "Epoch 110: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1176 - accuracy: 0.9578 - val_loss: 0.9597 - val_accuracy: 0.7200\n",
      "Epoch 111/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0755 - accuracy: 0.9710\n",
      "Epoch 111: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0651 - accuracy: 0.9770 - val_loss: 0.9345 - val_accuracy: 0.7333\n",
      "Epoch 112/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0709 - accuracy: 0.9770\n",
      "Epoch 112: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0680 - accuracy: 0.9778 - val_loss: 0.9766 - val_accuracy: 0.7133\n",
      "Epoch 113/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0637 - accuracy: 0.9820\n",
      "Epoch 113: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0659 - accuracy: 0.9770 - val_loss: 1.0278 - val_accuracy: 0.7467\n",
      "Epoch 114/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0883 - accuracy: 0.9720\n",
      "Epoch 114: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0802 - accuracy: 0.9763 - val_loss: 0.9196 - val_accuracy: 0.7400\n",
      "Epoch 115/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0386 - accuracy: 0.9930\n",
      "Epoch 115: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0413 - accuracy: 0.9911 - val_loss: 1.0863 - val_accuracy: 0.7067\n",
      "Epoch 116/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0439 - accuracy: 0.9900\n",
      "Epoch 116: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0454 - accuracy: 0.9904 - val_loss: 1.1544 - val_accuracy: 0.7333\n",
      "Epoch 117/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0562 - accuracy: 0.9810\n",
      "Epoch 117: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0570 - accuracy: 0.9822 - val_loss: 0.9491 - val_accuracy: 0.7267\n",
      "Epoch 118/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0479 - accuracy: 0.9880\n",
      "Epoch 118: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0452 - accuracy: 0.9881 - val_loss: 1.0513 - val_accuracy: 0.7467\n",
      "Epoch 119/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0364 - accuracy: 0.9880\n",
      "Epoch 119: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0432 - accuracy: 0.9859 - val_loss: 0.9521 - val_accuracy: 0.7267\n",
      "Epoch 120/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.0520 - accuracy: 0.9850\n",
      "Epoch 120: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0562 - accuracy: 0.9830 - val_loss: 1.0369 - val_accuracy: 0.7400\n",
      "Epoch 121/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0491 - accuracy: 0.9860\n",
      "Epoch 121: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 1.0454 - val_accuracy: 0.7400\n",
      "Epoch 122/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0629 - accuracy: 0.9820\n",
      "Epoch 122: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0708 - accuracy: 0.9770 - val_loss: 1.3524 - val_accuracy: 0.7067\n",
      "Epoch 123/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0996 - accuracy: 0.9620\n",
      "Epoch 123: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0914 - accuracy: 0.9674 - val_loss: 0.9887 - val_accuracy: 0.7533\n",
      "Epoch 124/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0517 - accuracy: 0.9820\n",
      "Epoch 124: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0500 - accuracy: 0.9837 - val_loss: 1.0978 - val_accuracy: 0.7133\n",
      "Epoch 125/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0515 - accuracy: 0.9810\n",
      "Epoch 125: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 1.1158 - val_accuracy: 0.7267\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9881\n",
      "Epoch 126: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0465 - accuracy: 0.9881 - val_loss: 1.1442 - val_accuracy: 0.7333\n",
      "Epoch 127/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0333 - accuracy: 0.9920\n",
      "Epoch 127: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 1.1283 - val_accuracy: 0.7533\n",
      "Epoch 128/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0342 - accuracy: 0.9940\n",
      "Epoch 128: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0340 - accuracy: 0.9941 - val_loss: 1.2257 - val_accuracy: 0.7333\n",
      "Epoch 129/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0278 - accuracy: 0.9970\n",
      "Epoch 129: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0292 - accuracy: 0.9956 - val_loss: 0.9806 - val_accuracy: 0.7267\n",
      "Epoch 130/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0316 - accuracy: 0.9960\n",
      "Epoch 130: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0357 - accuracy: 0.9919 - val_loss: 1.1251 - val_accuracy: 0.7400\n",
      "Epoch 131/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0324 - accuracy: 0.9910\n",
      "Epoch 131: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 1.7856 - val_accuracy: 0.7000\n",
      "Epoch 132/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0627 - accuracy: 0.9800\n",
      "Epoch 132: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0621 - accuracy: 0.9785 - val_loss: 1.1393 - val_accuracy: 0.7000\n",
      "Epoch 133/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0593 - accuracy: 0.9780\n",
      "Epoch 133: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0688 - accuracy: 0.9756 - val_loss: 1.2582 - val_accuracy: 0.7333\n",
      "Epoch 134/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1683 - accuracy: 0.9300\n",
      "Epoch 134: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2033 - accuracy: 0.9244 - val_loss: 1.5413 - val_accuracy: 0.7133\n",
      "Epoch 135/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4183 - accuracy: 0.8510\n",
      "Epoch 135: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4151 - accuracy: 0.8496 - val_loss: 0.8974 - val_accuracy: 0.7333\n",
      "Epoch 136/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2820 - accuracy: 0.8900\n",
      "Epoch 136: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3301 - accuracy: 0.8674 - val_loss: 0.8139 - val_accuracy: 0.7600\n",
      "Epoch 137/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4105 - accuracy: 0.8270\n",
      "Epoch 137: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4109 - accuracy: 0.8237 - val_loss: 1.0406 - val_accuracy: 0.6733\n",
      "Epoch 138/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.2682 - accuracy: 0.9060\n",
      "Epoch 138: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2559 - accuracy: 0.9030 - val_loss: 0.8018 - val_accuracy: 0.7067\n",
      "Epoch 139/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1716 - accuracy: 0.9420\n",
      "Epoch 139: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1628 - accuracy: 0.9467 - val_loss: 0.8910 - val_accuracy: 0.7333\n",
      "Epoch 140/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.1090 - accuracy: 0.9590\n",
      "Epoch 140: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0985 - accuracy: 0.9659 - val_loss: 0.9346 - val_accuracy: 0.7000\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9674\n",
      "Epoch 141: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0827 - accuracy: 0.9674 - val_loss: 0.9801 - val_accuracy: 0.7133\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9889\n",
      "Epoch 142: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0458 - accuracy: 0.9889 - val_loss: 1.1416 - val_accuracy: 0.7333\n",
      "Epoch 143/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0429 - accuracy: 0.9880\n",
      "Epoch 143: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0449 - accuracy: 0.9874 - val_loss: 1.0813 - val_accuracy: 0.7133\n",
      "Epoch 144/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0342 - accuracy: 0.9940\n",
      "Epoch 144: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0309 - accuracy: 0.9948 - val_loss: 1.1174 - val_accuracy: 0.7000\n",
      "Epoch 145/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0292 - accuracy: 0.9950\n",
      "Epoch 145: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0288 - accuracy: 0.9948 - val_loss: 1.1920 - val_accuracy: 0.7067\n",
      "Epoch 146/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0217 - accuracy: 0.9980\n",
      "Epoch 146: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0219 - accuracy: 0.9978 - val_loss: 1.1400 - val_accuracy: 0.7133\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9978\n",
      "Epoch 147: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0209 - accuracy: 0.9978 - val_loss: 1.1995 - val_accuracy: 0.7200\n",
      "Epoch 148/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0191 - accuracy: 0.9960\n",
      "Epoch 148: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0185 - accuracy: 0.9963 - val_loss: 1.2192 - val_accuracy: 0.7067\n",
      "Epoch 149/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.0180 - accuracy: 0.9975\n",
      "Epoch 149: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0191 - accuracy: 0.9970 - val_loss: 1.1865 - val_accuracy: 0.7267\n",
      "Epoch 150/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0193 - accuracy: 0.9970\n",
      "Epoch 150: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0208 - accuracy: 0.9970 - val_loss: 1.3360 - val_accuracy: 0.6933\n",
      "Epoch 151/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0187 - accuracy: 0.9980\n",
      "Epoch 151: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0183 - accuracy: 0.9985 - val_loss: 1.2311 - val_accuracy: 0.7067\n",
      "Epoch 152/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.0141 - accuracy: 0.9987\n",
      "Epoch 152: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0137 - accuracy: 0.9993 - val_loss: 1.1891 - val_accuracy: 0.7400\n",
      "Epoch 153/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 153: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0127 - accuracy: 0.9993 - val_loss: 1.3003 - val_accuracy: 0.7067\n",
      "Epoch 154/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 154: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.7200\n",
      "Epoch 155/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0119 - accuracy: 0.9990\n",
      "Epoch 155: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 1.2744 - val_accuracy: 0.7200\n",
      "Epoch 156/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0137 - accuracy: 0.9970\n",
      "Epoch 156: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 1.2453 - val_accuracy: 0.7133\n",
      "Epoch 157/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0152 - accuracy: 0.9970\n",
      "Epoch 157: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 1.2777 - val_accuracy: 0.7133\n",
      "Epoch 158/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.0106 - accuracy: 0.9987\n",
      "Epoch 158: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0122 - accuracy: 0.9985 - val_loss: 1.2793 - val_accuracy: 0.7267\n",
      "Epoch 159/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0118 - accuracy: 0.9980\n",
      "Epoch 159: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 1.2463 - val_accuracy: 0.7267\n",
      "Epoch 160/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 160: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.2886 - val_accuracy: 0.7067\n",
      "Epoch 161/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0135 - accuracy: 0.9990\n",
      "Epoch 161: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0119 - accuracy: 0.9993 - val_loss: 1.2890 - val_accuracy: 0.7200\n",
      "Epoch 162/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0100 - accuracy: 0.9980\n",
      "Epoch 162: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 1.2497 - val_accuracy: 0.7133\n",
      "Epoch 163/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 163: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 1.3128 - val_accuracy: 0.7200\n",
      "Epoch 164/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 164: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.2981 - val_accuracy: 0.7133\n",
      "Epoch 165/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 165: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.3567 - val_accuracy: 0.7133\n",
      "Epoch 166/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 166: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2758 - val_accuracy: 0.7333\n",
      "Epoch 167/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 167: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2875 - val_accuracy: 0.7267\n",
      "Epoch 168/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 168: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2688 - val_accuracy: 0.7067\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9963\n",
      "Epoch 169: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 1.3163 - val_accuracy: 0.7267\n",
      "Epoch 170/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0232 - accuracy: 0.9940\n",
      "Epoch 170: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 1.3232 - val_accuracy: 0.6933\n",
      "Epoch 171/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0241 - accuracy: 0.9920\n",
      "Epoch 171: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 1.2875 - val_accuracy: 0.7267\n",
      "Epoch 172/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0157 - accuracy: 0.9960\n",
      "Epoch 172: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 1.3511 - val_accuracy: 0.7400\n",
      "Epoch 173/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0084 - accuracy: 0.9990\n",
      "Epoch 173: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0122 - accuracy: 0.9978 - val_loss: 1.3434 - val_accuracy: 0.7333\n",
      "Epoch 174/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0103 - accuracy: 0.9980\n",
      "Epoch 174: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 1.3647 - val_accuracy: 0.7133\n",
      "Epoch 175/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 175: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.7133\n",
      "Epoch 176/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 176: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.7200\n",
      "Epoch 177/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0090 - accuracy: 0.9990\n",
      "Epoch 177: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 1.2903 - val_accuracy: 0.7267\n",
      "Epoch 178/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 178: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.3460 - val_accuracy: 0.7333\n",
      "Epoch 179/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 179: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.7267\n",
      "Epoch 180/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 180: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3133 - val_accuracy: 0.7200\n",
      "Epoch 181/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 181: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.7333\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 182: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.7400\n",
      "Epoch 183/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 183: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3855 - val_accuracy: 0.7267\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 184: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.7400\n",
      "Epoch 185/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 185: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3779 - val_accuracy: 0.7267\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 186: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4025 - val_accuracy: 0.7267\n",
      "Epoch 187/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 187: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3949 - val_accuracy: 0.7333\n",
      "Epoch 188/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 188: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4017 - val_accuracy: 0.7333\n",
      "Epoch 189/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 189: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3870 - val_accuracy: 0.7267\n",
      "Epoch 190/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 190: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4199 - val_accuracy: 0.7267\n",
      "Epoch 191/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 191: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3835 - val_accuracy: 0.7267\n",
      "Epoch 192/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 192: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.4463 - val_accuracy: 0.7267\n",
      "Epoch 193/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 193: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.4222 - val_accuracy: 0.7267\n",
      "Epoch 194/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 194: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.4356 - val_accuracy: 0.7400\n",
      "Epoch 195/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 195: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4263 - val_accuracy: 0.7267\n",
      "Epoch 196/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 196: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4354 - val_accuracy: 0.7333\n",
      "Epoch 197/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 197: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4226 - val_accuracy: 0.7333\n",
      "Epoch 198/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 198: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4354 - val_accuracy: 0.7267\n",
      "Epoch 199/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 199: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4765 - val_accuracy: 0.7267\n",
      "Epoch 200/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 200: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4224 - val_accuracy: 0.7133\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 201: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5094 - val_accuracy: 0.7267\n",
      "Epoch 202/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 202: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4520 - val_accuracy: 0.7400\n",
      "Epoch 203/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 203: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4706 - val_accuracy: 0.7400\n",
      "Epoch 204/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 204: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4864 - val_accuracy: 0.7267\n",
      "Epoch 205/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 205: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4704 - val_accuracy: 0.7267\n",
      "Epoch 206/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 206: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5122 - val_accuracy: 0.7200\n",
      "Epoch 207/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 207: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4498 - val_accuracy: 0.7333\n",
      "Epoch 208/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 208: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.7200\n",
      "Epoch 209/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 209: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5139 - val_accuracy: 0.7200\n",
      "Epoch 210/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 210: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4923 - val_accuracy: 0.7333\n",
      "Epoch 211/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000    \n",
      "Epoch 211: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5015 - val_accuracy: 0.7200\n",
      "Epoch 212/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 212: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4977 - val_accuracy: 0.7267\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 213: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5381 - val_accuracy: 0.7267\n",
      "Epoch 214/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 214: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5056 - val_accuracy: 0.7200\n",
      "Epoch 215/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 215: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5084 - val_accuracy: 0.7333\n",
      "Epoch 216/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 216: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5449 - val_accuracy: 0.7200\n",
      "Epoch 217/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 217: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4991 - val_accuracy: 0.7267\n",
      "Epoch 218/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 218: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5366 - val_accuracy: 0.7200\n",
      "Epoch 219/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 219: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5350 - val_accuracy: 0.7200\n",
      "Epoch 220/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 220: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5155 - val_accuracy: 0.7267\n",
      "Epoch 221/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 221: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5477 - val_accuracy: 0.7267\n",
      "Epoch 222/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 222: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5351 - val_accuracy: 0.7333\n",
      "Epoch 223/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 223: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5734 - val_accuracy: 0.7133\n",
      "Epoch 224/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 224: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5360 - val_accuracy: 0.7200\n",
      "Epoch 225/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 225: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5657 - val_accuracy: 0.7200\n",
      "Epoch 226/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 226: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5321 - val_accuracy: 0.7200\n",
      "Epoch 227/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 227: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.7267\n",
      "Epoch 228/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 228: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5298 - val_accuracy: 0.7267\n",
      "Epoch 229/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 229: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6004 - val_accuracy: 0.7267\n",
      "Epoch 230/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 230: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.5333 - val_accuracy: 0.7267\n",
      "Epoch 231/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 231: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5528 - val_accuracy: 0.7333\n",
      "Epoch 232/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 232: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5746 - val_accuracy: 0.7133\n",
      "Epoch 233/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    \n",
      "Epoch 233: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.5731 - val_accuracy: 0.7200\n",
      "Epoch 234/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.4943e-04 - accuracy: 1.0000\n",
      "Epoch 234: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.4275e-04 - accuracy: 1.0000 - val_loss: 1.5819 - val_accuracy: 0.7200\n",
      "Epoch 235/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.7862e-04 - accuracy: 1.0000\n",
      "Epoch 235: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.4468e-04 - accuracy: 1.0000 - val_loss: 1.5649 - val_accuracy: 0.7267\n",
      "Epoch 236/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.3208e-04 - accuracy: 1.0000\n",
      "Epoch 236: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.0462e-04 - accuracy: 1.0000 - val_loss: 1.5589 - val_accuracy: 0.7333\n",
      "Epoch 237/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.0303e-04 - accuracy: 1.0000\n",
      "Epoch 237: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.7865e-04 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.7200\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 8.8811e-04 - accuracy: 1.0000\n",
      "Epoch 238: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 8.8811e-04 - accuracy: 1.0000 - val_loss: 1.5751 - val_accuracy: 0.7333\n",
      "Epoch 239/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.2034e-04 - accuracy: 1.0000\n",
      "Epoch 239: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.5808e-04 - accuracy: 1.0000 - val_loss: 1.5805 - val_accuracy: 0.7200\n",
      "Epoch 240/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.9407e-04 - accuracy: 1.0000\n",
      "Epoch 240: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.4089e-04 - accuracy: 1.0000 - val_loss: 1.5749 - val_accuracy: 0.7333\n",
      "Epoch 241/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.7216e-04 - accuracy: 1.0000\n",
      "Epoch 241: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.2549e-04 - accuracy: 1.0000 - val_loss: 1.5864 - val_accuracy: 0.7333\n",
      "Epoch 242/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.1121e-04 - accuracy: 1.0000\n",
      "Epoch 242: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.2534e-04 - accuracy: 1.0000 - val_loss: 1.5948 - val_accuracy: 0.7200\n",
      "Epoch 243/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.5986e-04 - accuracy: 1.0000\n",
      "Epoch 243: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.2829e-04 - accuracy: 1.0000 - val_loss: 1.5801 - val_accuracy: 0.7200\n",
      "Epoch 244/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.1442e-04 - accuracy: 1.0000\n",
      "Epoch 244: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.7179e-04 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.7200\n",
      "Epoch 245/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.0422e-04 - accuracy: 1.0000\n",
      "Epoch 245: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.8049e-04 - accuracy: 1.0000 - val_loss: 1.5898 - val_accuracy: 0.7200\n",
      "Epoch 246/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.4763e-04 - accuracy: 1.0000\n",
      "Epoch 246: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.1579e-04 - accuracy: 1.0000 - val_loss: 1.5857 - val_accuracy: 0.7333\n",
      "Epoch 247/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.9730e-04 - accuracy: 1.0000\n",
      "Epoch 247: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.5996e-04 - accuracy: 1.0000 - val_loss: 1.6160 - val_accuracy: 0.7333\n",
      "Epoch 248/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.9288e-04 - accuracy: 1.0000\n",
      "Epoch 248: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 7.3352e-04 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.7333\n",
      "Epoch 249/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.6903e-04 - accuracy: 1.0000\n",
      "Epoch 249: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 7.4081e-04 - accuracy: 1.0000 - val_loss: 1.6054 - val_accuracy: 0.7267\n",
      "Epoch 250/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.4028e-04 - accuracy: 1.0000\n",
      "Epoch 250: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 7.5937e-04 - accuracy: 1.0000 - val_loss: 1.5962 - val_accuracy: 0.7267\n",
      "Epoch 251/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.7689e-04 - accuracy: 1.0000\n",
      "Epoch 251: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.3024e-04 - accuracy: 1.0000 - val_loss: 1.6095 - val_accuracy: 0.7333\n",
      "Epoch 252/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.6710e-04 - accuracy: 1.0000\n",
      "Epoch 252: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 7.1511e-04 - accuracy: 1.0000 - val_loss: 1.6014 - val_accuracy: 0.7333\n",
      "Epoch 253/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.8503e-04 - accuracy: 1.0000\n",
      "Epoch 253: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 7.2067e-04 - accuracy: 1.0000 - val_loss: 1.6069 - val_accuracy: 0.7267\n",
      "Epoch 254/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.8729e-04 - accuracy: 1.0000\n",
      "Epoch 254: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 7.1045e-04 - accuracy: 1.0000 - val_loss: 1.6097 - val_accuracy: 0.7333\n",
      "Epoch 255/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.4904e-04 - accuracy: 1.0000\n",
      "Epoch 255: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 6.9117e-04 - accuracy: 1.0000 - val_loss: 1.6418 - val_accuracy: 0.7333\n",
      "Epoch 256/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.6250e-04 - accuracy: 1.0000\n",
      "Epoch 256: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 6.5811e-04 - accuracy: 1.0000 - val_loss: 1.5982 - val_accuracy: 0.7333\n",
      "Epoch 257/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.9912e-04 - accuracy: 1.0000\n",
      "Epoch 257: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 6.7679e-04 - accuracy: 1.0000 - val_loss: 1.6164 - val_accuracy: 0.7267\n",
      "Epoch 258/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.1554e-04 - accuracy: 1.0000\n",
      "Epoch 258: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 6.5074e-04 - accuracy: 1.0000 - val_loss: 1.6288 - val_accuracy: 0.7333\n",
      "Epoch 259/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.2106e-04 - accuracy: 1.0000\n",
      "Epoch 259: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 6.2654e-04 - accuracy: 1.0000 - val_loss: 1.6166 - val_accuracy: 0.7333\n",
      "Epoch 260/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.6896e-04 - accuracy: 1.0000\n",
      "Epoch 260: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 6.2963e-04 - accuracy: 1.0000 - val_loss: 1.6176 - val_accuracy: 0.7333\n",
      "Epoch 261/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 5.7114e-04 - accuracy: 1.0000\n",
      "Epoch 261: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 6.1065e-04 - accuracy: 1.0000 - val_loss: 1.6331 - val_accuracy: 0.7333\n",
      "Epoch 262/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.0499e-04 - accuracy: 1.0000\n",
      "Epoch 262: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 6.0745e-04 - accuracy: 1.0000 - val_loss: 1.6309 - val_accuracy: 0.7267\n",
      "Epoch 263/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.6239e-04 - accuracy: 1.0000\n",
      "Epoch 263: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 6.1220e-04 - accuracy: 1.0000 - val_loss: 1.6356 - val_accuracy: 0.7333\n",
      "Epoch 264/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.3683e-04 - accuracy: 1.0000\n",
      "Epoch 264: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.8495e-04 - accuracy: 1.0000 - val_loss: 1.6294 - val_accuracy: 0.7333\n",
      "Epoch 265/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.9229e-04 - accuracy: 1.0000\n",
      "Epoch 265: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.7357e-04 - accuracy: 1.0000 - val_loss: 1.6442 - val_accuracy: 0.7333\n",
      "Epoch 266/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.9612e-04 - accuracy: 1.0000\n",
      "Epoch 266: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.7172e-04 - accuracy: 1.0000 - val_loss: 1.6295 - val_accuracy: 0.7333\n",
      "Epoch 267/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.8698e-04 - accuracy: 1.0000\n",
      "Epoch 267: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.8182e-04 - accuracy: 1.0000 - val_loss: 1.6436 - val_accuracy: 0.7267\n",
      "Epoch 268/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.8682e-04 - accuracy: 1.0000\n",
      "Epoch 268: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.6895e-04 - accuracy: 1.0000 - val_loss: 1.6366 - val_accuracy: 0.7200\n",
      "Epoch 269/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 5.4930e-04 - accuracy: 1.0000\n",
      "Epoch 269: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 5.7276e-04 - accuracy: 1.0000 - val_loss: 1.6582 - val_accuracy: 0.7200\n",
      "Epoch 270/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.1519e-04 - accuracy: 1.0000\n",
      "Epoch 270: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 6.6301e-04 - accuracy: 1.0000 - val_loss: 1.6295 - val_accuracy: 0.7267\n",
      "Epoch 271/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.2888e-04 - accuracy: 1.0000\n",
      "Epoch 271: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.8276e-04 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 0.7333\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 6.1002e-04 - accuracy: 1.0000\n",
      "Epoch 272: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 6.1002e-04 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.7267\n",
      "Epoch 273/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.3553e-04 - accuracy: 1.0000\n",
      "Epoch 273: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 6.6826e-04 - accuracy: 1.0000 - val_loss: 1.6458 - val_accuracy: 0.7133\n",
      "Epoch 274/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.4321e-04 - accuracy: 1.0000\n",
      "Epoch 274: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 6.9629e-04 - accuracy: 1.0000 - val_loss: 1.6829 - val_accuracy: 0.7200\n",
      "Epoch 275/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.8059e-04 - accuracy: 1.0000\n",
      "Epoch 275: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.9125e-04 - accuracy: 1.0000 - val_loss: 1.6497 - val_accuracy: 0.7200\n",
      "Epoch 276/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.2930e-04 - accuracy: 1.0000\n",
      "Epoch 276: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 5.4841e-04 - accuracy: 1.0000 - val_loss: 1.6633 - val_accuracy: 0.7200\n",
      "Epoch 277/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.8014e-04 - accuracy: 1.0000\n",
      "Epoch 277: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.2733e-04 - accuracy: 1.0000 - val_loss: 1.6607 - val_accuracy: 0.7267\n",
      "Epoch 278/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.1781e-04 - accuracy: 1.0000\n",
      "Epoch 278: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 4.9610e-04 - accuracy: 1.0000 - val_loss: 1.6719 - val_accuracy: 0.7267\n",
      "Epoch 279/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.7105e-04 - accuracy: 1.0000\n",
      "Epoch 279: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 5.2435e-04 - accuracy: 1.0000 - val_loss: 1.6642 - val_accuracy: 0.7333\n",
      "Epoch 280/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.9912e-04 - accuracy: 1.0000\n",
      "Epoch 280: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.4990e-04 - accuracy: 1.0000 - val_loss: 1.6528 - val_accuracy: 0.7333\n",
      "Epoch 281/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.9029e-04 - accuracy: 1.0000\n",
      "Epoch 281: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.4974e-04 - accuracy: 1.0000 - val_loss: 1.6745 - val_accuracy: 0.7200\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 5.7112e-04 - accuracy: 1.0000\n",
      "Epoch 282: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 5.7112e-04 - accuracy: 1.0000 - val_loss: 1.6662 - val_accuracy: 0.7133\n",
      "Epoch 283/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.7751e-04 - accuracy: 1.0000\n",
      "Epoch 283: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 5.7451e-04 - accuracy: 1.0000 - val_loss: 1.6918 - val_accuracy: 0.7200\n",
      "Epoch 284/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.8101e-04 - accuracy: 1.0000\n",
      "Epoch 284: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 4.8056e-04 - accuracy: 1.0000 - val_loss: 1.6838 - val_accuracy: 0.7133\n",
      "Epoch 285/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.9795e-04 - accuracy: 1.0000\n",
      "Epoch 285: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 4.9216e-04 - accuracy: 1.0000 - val_loss: 1.6944 - val_accuracy: 0.7200\n",
      "Epoch 286/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 5.0579e-04 - accuracy: 1.0000\n",
      "Epoch 286: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 4.6914e-04 - accuracy: 1.0000 - val_loss: 1.6938 - val_accuracy: 0.7333\n",
      "Epoch 287/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.4498e-04 - accuracy: 1.0000\n",
      "Epoch 287: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.2847e-04 - accuracy: 1.0000 - val_loss: 1.6919 - val_accuracy: 0.7333\n",
      "Epoch 288/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.7645e-04 - accuracy: 1.0000\n",
      "Epoch 288: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.2822e-04 - accuracy: 1.0000 - val_loss: 1.6851 - val_accuracy: 0.7333\n",
      "Epoch 289/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.4373e-04 - accuracy: 1.0000\n",
      "Epoch 289: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.2643e-04 - accuracy: 1.0000 - val_loss: 1.6979 - val_accuracy: 0.7333\n",
      "Epoch 290/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.1052e-04 - accuracy: 1.0000\n",
      "Epoch 290: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.1668e-04 - accuracy: 1.0000 - val_loss: 1.6854 - val_accuracy: 0.7333\n",
      "Epoch 291/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.8367e-04 - accuracy: 1.0000\n",
      "Epoch 291: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 4.0744e-04 - accuracy: 1.0000 - val_loss: 1.6977 - val_accuracy: 0.7333\n",
      "Epoch 292/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.9435e-04 - accuracy: 1.0000\n",
      "Epoch 292: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.1838e-04 - accuracy: 1.0000 - val_loss: 1.6951 - val_accuracy: 0.7333\n",
      "Epoch 293/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 3.8584e-04 - accuracy: 1.0000\n",
      "Epoch 293: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 4.0454e-04 - accuracy: 1.0000 - val_loss: 1.6858 - val_accuracy: 0.7333\n",
      "Epoch 294/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.9098e-04 - accuracy: 1.0000\n",
      "Epoch 294: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.9820e-04 - accuracy: 1.0000 - val_loss: 1.7054 - val_accuracy: 0.7333\n",
      "Epoch 295/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.7033e-04 - accuracy: 1.0000\n",
      "Epoch 295: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.9372e-04 - accuracy: 1.0000 - val_loss: 1.7160 - val_accuracy: 0.7333\n",
      "Epoch 296/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.9247e-04 - accuracy: 1.0000\n",
      "Epoch 296: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 3.9176e-04 - accuracy: 1.0000 - val_loss: 1.6890 - val_accuracy: 0.7400\n",
      "Epoch 297/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 4.1564e-04 - accuracy: 1.0000\n",
      "Epoch 297: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.8588e-04 - accuracy: 1.0000 - val_loss: 1.7103 - val_accuracy: 0.7400\n",
      "Epoch 298/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.3286e-04 - accuracy: 1.0000\n",
      "Epoch 298: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.7828e-04 - accuracy: 1.0000 - val_loss: 1.6949 - val_accuracy: 0.7400\n",
      "Epoch 299/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.4282e-04 - accuracy: 1.0000\n",
      "Epoch 299: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.8707e-04 - accuracy: 1.0000 - val_loss: 1.7114 - val_accuracy: 0.7333\n",
      "Epoch 300/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.4496e-04 - accuracy: 1.0000\n",
      "Epoch 300: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.7389e-04 - accuracy: 1.0000 - val_loss: 1.7122 - val_accuracy: 0.7333\n",
      "Epoch 301/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.4794e-04 - accuracy: 1.0000\n",
      "Epoch 301: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.7955e-04 - accuracy: 1.0000 - val_loss: 1.7076 - val_accuracy: 0.7333\n",
      "Epoch 302/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.7122e-04 - accuracy: 1.0000\n",
      "Epoch 302: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.7214e-04 - accuracy: 1.0000 - val_loss: 1.7129 - val_accuracy: 0.7333\n",
      "Epoch 303/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.2498e-04 - accuracy: 1.0000\n",
      "Epoch 303: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 3.5909e-04 - accuracy: 1.0000 - val_loss: 1.7140 - val_accuracy: 0.7333\n",
      "Epoch 304/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.1844e-04 - accuracy: 1.0000\n",
      "Epoch 304: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.4938e-04 - accuracy: 1.0000 - val_loss: 1.7234 - val_accuracy: 0.7333\n",
      "Epoch 305/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.4676e-04 - accuracy: 1.0000\n",
      "Epoch 305: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.5020e-04 - accuracy: 1.0000 - val_loss: 1.7255 - val_accuracy: 0.7333\n",
      "Epoch 306/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.2915e-04 - accuracy: 1.0000\n",
      "Epoch 306: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 3.4353e-04 - accuracy: 1.0000 - val_loss: 1.7172 - val_accuracy: 0.7333\n",
      "Epoch 307/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.6818e-04 - accuracy: 1.0000\n",
      "Epoch 307: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.5061e-04 - accuracy: 1.0000 - val_loss: 1.7250 - val_accuracy: 0.7333\n",
      "Epoch 308/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.0210e-04 - accuracy: 1.0000\n",
      "Epoch 308: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.3794e-04 - accuracy: 1.0000 - val_loss: 1.7247 - val_accuracy: 0.7267\n",
      "Epoch 309/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.5749e-04 - accuracy: 1.0000\n",
      "Epoch 309: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.3402e-04 - accuracy: 1.0000 - val_loss: 1.7266 - val_accuracy: 0.7333\n",
      "Epoch 310/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.2505e-04 - accuracy: 1.0000\n",
      "Epoch 310: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.3058e-04 - accuracy: 1.0000 - val_loss: 1.7217 - val_accuracy: 0.7333\n",
      "Epoch 311/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.2561e-04 - accuracy: 1.0000\n",
      "Epoch 311: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.3082e-04 - accuracy: 1.0000 - val_loss: 1.7334 - val_accuracy: 0.7333\n",
      "Epoch 312/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.7985e-04 - accuracy: 1.0000\n",
      "Epoch 312: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.2006e-04 - accuracy: 1.0000 - val_loss: 1.7283 - val_accuracy: 0.7333\n",
      "Epoch 313/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.1949e-04 - accuracy: 1.0000\n",
      "Epoch 313: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.1902e-04 - accuracy: 1.0000 - val_loss: 1.7411 - val_accuracy: 0.7333\n",
      "Epoch 314/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 2.8641e-04 - accuracy: 1.0000\n",
      "Epoch 314: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.1705e-04 - accuracy: 1.0000 - val_loss: 1.7315 - val_accuracy: 0.7333\n",
      "Epoch 315/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.1406e-04 - accuracy: 1.0000\n",
      "Epoch 315: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.1104e-04 - accuracy: 1.0000 - val_loss: 1.7430 - val_accuracy: 0.7400\n",
      "Epoch 316/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.9392e-04 - accuracy: 1.0000\n",
      "Epoch 316: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.1378e-04 - accuracy: 1.0000 - val_loss: 1.7390 - val_accuracy: 0.7333\n",
      "Epoch 317/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.0629e-04 - accuracy: 1.0000\n",
      "Epoch 317: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.0749e-04 - accuracy: 1.0000 - val_loss: 1.7445 - val_accuracy: 0.7333\n",
      "Epoch 318/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.9703e-04 - accuracy: 1.0000\n",
      "Epoch 318: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.1032e-04 - accuracy: 1.0000 - val_loss: 1.7444 - val_accuracy: 0.7333\n",
      "Epoch 319/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.2785e-04 - accuracy: 1.0000\n",
      "Epoch 319: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.1357e-04 - accuracy: 1.0000 - val_loss: 1.7419 - val_accuracy: 0.7400\n",
      "Epoch 320/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.9675e-04 - accuracy: 1.0000\n",
      "Epoch 320: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.0342e-04 - accuracy: 1.0000 - val_loss: 1.7514 - val_accuracy: 0.7333\n",
      "Epoch 321/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 3.1987e-04 - accuracy: 1.0000\n",
      "Epoch 321: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.9537e-04 - accuracy: 1.0000 - val_loss: 1.7581 - val_accuracy: 0.7400\n",
      "Epoch 322/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.8276e-04 - accuracy: 1.0000\n",
      "Epoch 322: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.9157e-04 - accuracy: 1.0000 - val_loss: 1.7516 - val_accuracy: 0.7400\n",
      "Epoch 323/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.8191e-04 - accuracy: 1.0000\n",
      "Epoch 323: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.9113e-04 - accuracy: 1.0000 - val_loss: 1.7494 - val_accuracy: 0.7400\n",
      "Epoch 324/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.8752e-04 - accuracy: 1.0000\n",
      "Epoch 324: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.8474e-04 - accuracy: 1.0000 - val_loss: 1.7645 - val_accuracy: 0.7400\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.8202e-04 - accuracy: 1.0000\n",
      "Epoch 325: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.8202e-04 - accuracy: 1.0000 - val_loss: 1.7575 - val_accuracy: 0.7400\n",
      "Epoch 326/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.7264e-04 - accuracy: 1.0000\n",
      "Epoch 326: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.8055e-04 - accuracy: 1.0000 - val_loss: 1.7568 - val_accuracy: 0.7333\n",
      "Epoch 327/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.7138e-04 - accuracy: 1.0000\n",
      "Epoch 327: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.8076e-04 - accuracy: 1.0000 - val_loss: 1.7638 - val_accuracy: 0.7400\n",
      "Epoch 328/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.7583e-04 - accuracy: 1.0000\n",
      "Epoch 328: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.7047e-04 - accuracy: 1.0000 - val_loss: 1.7659 - val_accuracy: 0.7400\n",
      "Epoch 329/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.4005e-04 - accuracy: 1.0000\n",
      "Epoch 329: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.7036e-04 - accuracy: 1.0000 - val_loss: 1.7649 - val_accuracy: 0.7400\n",
      "Epoch 330/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.7011e-04 - accuracy: 1.0000\n",
      "Epoch 330: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.6835e-04 - accuracy: 1.0000 - val_loss: 1.7701 - val_accuracy: 0.7267\n",
      "Epoch 331/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.4907e-04 - accuracy: 1.0000\n",
      "Epoch 331: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.6016e-04 - accuracy: 1.0000 - val_loss: 1.7801 - val_accuracy: 0.7400\n",
      "Epoch 332/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.7355e-04 - accuracy: 1.0000\n",
      "Epoch 332: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.6986e-04 - accuracy: 1.0000 - val_loss: 1.7585 - val_accuracy: 0.7333\n",
      "Epoch 333/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.7707e-04 - accuracy: 1.0000\n",
      "Epoch 333: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.6311e-04 - accuracy: 1.0000 - val_loss: 1.7798 - val_accuracy: 0.7400\n",
      "Epoch 334/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.6022e-04 - accuracy: 1.0000\n",
      "Epoch 334: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.5853e-04 - accuracy: 1.0000 - val_loss: 1.7805 - val_accuracy: 0.7400\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.5124e-04 - accuracy: 1.0000\n",
      "Epoch 335: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.5124e-04 - accuracy: 1.0000 - val_loss: 1.7751 - val_accuracy: 0.7400\n",
      "Epoch 336/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.6675e-04 - accuracy: 1.0000\n",
      "Epoch 336: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.5451e-04 - accuracy: 1.0000 - val_loss: 1.7782 - val_accuracy: 0.7400\n",
      "Epoch 337/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.4582e-04 - accuracy: 1.0000\n",
      "Epoch 337: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.4782e-04 - accuracy: 1.0000 - val_loss: 1.7848 - val_accuracy: 0.7400\n",
      "Epoch 338/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.2419e-04 - accuracy: 1.0000\n",
      "Epoch 338: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.4726e-04 - accuracy: 1.0000 - val_loss: 1.7804 - val_accuracy: 0.7400\n",
      "Epoch 339/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.3148e-04 - accuracy: 1.0000\n",
      "Epoch 339: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.5656e-04 - accuracy: 1.0000 - val_loss: 1.7877 - val_accuracy: 0.7400\n",
      "Epoch 340/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.8006e-04 - accuracy: 1.0000\n",
      "Epoch 340: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.6624e-04 - accuracy: 1.0000 - val_loss: 1.7832 - val_accuracy: 0.7467\n",
      "Epoch 341/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.4182e-04 - accuracy: 1.0000\n",
      "Epoch 341: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.4504e-04 - accuracy: 1.0000 - val_loss: 1.7812 - val_accuracy: 0.7400\n",
      "Epoch 342/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.4245e-04 - accuracy: 1.0000\n",
      "Epoch 342: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.4031e-04 - accuracy: 1.0000 - val_loss: 1.7832 - val_accuracy: 0.7333\n",
      "Epoch 343/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.3127e-04 - accuracy: 1.0000\n",
      "Epoch 343: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.4407e-04 - accuracy: 1.0000 - val_loss: 1.7982 - val_accuracy: 0.7400\n",
      "Epoch 344/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.2366e-04 - accuracy: 1.0000\n",
      "Epoch 344: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.4434e-04 - accuracy: 1.0000 - val_loss: 1.7967 - val_accuracy: 0.7400\n",
      "Epoch 345/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.1940e-04 - accuracy: 1.0000\n",
      "Epoch 345: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.3550e-04 - accuracy: 1.0000 - val_loss: 1.7824 - val_accuracy: 0.7333\n",
      "Epoch 346/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.3719e-04 - accuracy: 1.0000\n",
      "Epoch 346: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.2925e-04 - accuracy: 1.0000 - val_loss: 1.8043 - val_accuracy: 0.7400\n",
      "Epoch 347/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.3170e-04 - accuracy: 1.0000\n",
      "Epoch 347: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2691e-04 - accuracy: 1.0000 - val_loss: 1.7990 - val_accuracy: 0.7400\n",
      "Epoch 348/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.0612e-04 - accuracy: 1.0000\n",
      "Epoch 348: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.2860e-04 - accuracy: 1.0000 - val_loss: 1.7984 - val_accuracy: 0.7467\n",
      "Epoch 349/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.2025e-04 - accuracy: 1.0000\n",
      "Epoch 349: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 2.1978e-04 - accuracy: 1.0000 - val_loss: 1.8012 - val_accuracy: 0.7400\n",
      "Epoch 350/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.1098e-04 - accuracy: 1.0000\n",
      "Epoch 350: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.1959e-04 - accuracy: 1.0000 - val_loss: 1.7964 - val_accuracy: 0.7467\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.1919e-04 - accuracy: 1.0000\n",
      "Epoch 351: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.1919e-04 - accuracy: 1.0000 - val_loss: 1.8125 - val_accuracy: 0.7400\n",
      "Epoch 352/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.3588e-04 - accuracy: 1.0000\n",
      "Epoch 352: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.1601e-04 - accuracy: 1.0000 - val_loss: 1.7983 - val_accuracy: 0.7333\n",
      "Epoch 353/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.9583e-04 - accuracy: 1.0000\n",
      "Epoch 353: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.1447e-04 - accuracy: 1.0000 - val_loss: 1.8091 - val_accuracy: 0.7467\n",
      "Epoch 354/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.8880e-04 - accuracy: 1.0000\n",
      "Epoch 354: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.0796e-04 - accuracy: 1.0000 - val_loss: 1.8038 - val_accuracy: 0.7400\n",
      "Epoch 355/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.1763e-04 - accuracy: 1.0000\n",
      "Epoch 355: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.1285e-04 - accuracy: 1.0000 - val_loss: 1.8180 - val_accuracy: 0.7467\n",
      "Epoch 356/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.0772e-04 - accuracy: 1.0000\n",
      "Epoch 356: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.0808e-04 - accuracy: 1.0000 - val_loss: 1.8055 - val_accuracy: 0.7400\n",
      "Epoch 357/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.9974e-04 - accuracy: 1.0000\n",
      "Epoch 357: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.0597e-04 - accuracy: 1.0000 - val_loss: 1.8210 - val_accuracy: 0.7400\n",
      "Epoch 358/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.8054e-04 - accuracy: 1.0000\n",
      "Epoch 358: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.0370e-04 - accuracy: 1.0000 - val_loss: 1.8113 - val_accuracy: 0.7400\n",
      "Epoch 359/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.9553e-04 - accuracy: 1.0000\n",
      "Epoch 359: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.0177e-04 - accuracy: 1.0000 - val_loss: 1.8106 - val_accuracy: 0.7333\n",
      "Epoch 360/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.1037e-04 - accuracy: 1.0000\n",
      "Epoch 360: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.9928e-04 - accuracy: 1.0000 - val_loss: 1.8338 - val_accuracy: 0.7400\n",
      "Epoch 361/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.9630e-04 - accuracy: 1.0000\n",
      "Epoch 361: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.9863e-04 - accuracy: 1.0000 - val_loss: 1.8203 - val_accuracy: 0.7467\n",
      "Epoch 362/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.1477e-04 - accuracy: 1.0000\n",
      "Epoch 362: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.9718e-04 - accuracy: 1.0000 - val_loss: 1.8191 - val_accuracy: 0.7467\n",
      "Epoch 363/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 2.1718e-04 - accuracy: 1.0000\n",
      "Epoch 363: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.9319e-04 - accuracy: 1.0000 - val_loss: 1.8231 - val_accuracy: 0.7400\n",
      "Epoch 364/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.9880e-04 - accuracy: 1.0000\n",
      "Epoch 364: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.9268e-04 - accuracy: 1.0000 - val_loss: 1.8295 - val_accuracy: 0.7400\n",
      "Epoch 365/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.9522e-04 - accuracy: 1.0000\n",
      "Epoch 365: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.9104e-04 - accuracy: 1.0000 - val_loss: 1.8232 - val_accuracy: 0.7467\n",
      "Epoch 366/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.7718e-04 - accuracy: 1.0000\n",
      "Epoch 366: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.9066e-04 - accuracy: 1.0000 - val_loss: 1.8231 - val_accuracy: 0.7467\n",
      "Epoch 367/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.8134e-04 - accuracy: 1.0000\n",
      "Epoch 367: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.8840e-04 - accuracy: 1.0000 - val_loss: 1.8277 - val_accuracy: 0.7400\n",
      "Epoch 368/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4695e-04 - accuracy: 1.0000\n",
      "Epoch 368: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.8679e-04 - accuracy: 1.0000 - val_loss: 1.8408 - val_accuracy: 0.7467\n",
      "Epoch 369/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.5243e-04 - accuracy: 1.0000\n",
      "Epoch 369: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.8200e-04 - accuracy: 1.0000 - val_loss: 1.8313 - val_accuracy: 0.7467\n",
      "Epoch 370/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.9642e-04 - accuracy: 1.0000\n",
      "Epoch 370: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.8652e-04 - accuracy: 1.0000 - val_loss: 1.8351 - val_accuracy: 0.7467\n",
      "Epoch 371/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.6218e-04 - accuracy: 1.0000\n",
      "Epoch 371: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.8356e-04 - accuracy: 1.0000 - val_loss: 1.8379 - val_accuracy: 0.7467\n",
      "Epoch 372/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.5517e-04 - accuracy: 1.0000\n",
      "Epoch 372: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.7927e-04 - accuracy: 1.0000 - val_loss: 1.8348 - val_accuracy: 0.7400\n",
      "Epoch 373/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.7603e-04 - accuracy: 1.0000\n",
      "Epoch 373: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.8241e-04 - accuracy: 1.0000 - val_loss: 1.8440 - val_accuracy: 0.7467\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.7665e-04 - accuracy: 1.0000\n",
      "Epoch 374: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.7665e-04 - accuracy: 1.0000 - val_loss: 1.8377 - val_accuracy: 0.7400\n",
      "Epoch 375/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.7121e-04 - accuracy: 1.0000\n",
      "Epoch 375: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.7921e-04 - accuracy: 1.0000 - val_loss: 1.8530 - val_accuracy: 0.7467\n",
      "Epoch 376/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.6632e-04 - accuracy: 1.0000\n",
      "Epoch 376: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.7401e-04 - accuracy: 1.0000 - val_loss: 1.8403 - val_accuracy: 0.7400\n",
      "Epoch 377/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.7283e-04 - accuracy: 1.0000\n",
      "Epoch 377: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.7141e-04 - accuracy: 1.0000 - val_loss: 1.8411 - val_accuracy: 0.7467\n",
      "Epoch 378/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.6180e-04 - accuracy: 1.0000\n",
      "Epoch 378: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.7033e-04 - accuracy: 1.0000 - val_loss: 1.8479 - val_accuracy: 0.7467\n",
      "Epoch 379/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.7866e-04 - accuracy: 1.0000\n",
      "Epoch 379: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.6784e-04 - accuracy: 1.0000 - val_loss: 1.8548 - val_accuracy: 0.7467\n",
      "Epoch 380/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.7378e-04 - accuracy: 1.0000\n",
      "Epoch 380: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.6729e-04 - accuracy: 1.0000 - val_loss: 1.8604 - val_accuracy: 0.7467\n",
      "Epoch 381/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.8370e-04 - accuracy: 1.0000\n",
      "Epoch 381: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.6637e-04 - accuracy: 1.0000 - val_loss: 1.8542 - val_accuracy: 0.7467\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.6562e-04 - accuracy: 1.0000\n",
      "Epoch 382: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.6562e-04 - accuracy: 1.0000 - val_loss: 1.8462 - val_accuracy: 0.7467\n",
      "Epoch 383/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.5808e-04 - accuracy: 1.0000\n",
      "Epoch 383: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.6748e-04 - accuracy: 1.0000 - val_loss: 1.8590 - val_accuracy: 0.7467\n",
      "Epoch 384/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.6521e-04 - accuracy: 1.0000\n",
      "Epoch 384: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.7071e-04 - accuracy: 1.0000 - val_loss: 1.8580 - val_accuracy: 0.7400\n",
      "Epoch 385/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.5064e-04 - accuracy: 1.0000\n",
      "Epoch 385: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.5867e-04 - accuracy: 1.0000 - val_loss: 1.8688 - val_accuracy: 0.7467\n",
      "Epoch 386/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.3664e-04 - accuracy: 1.0000\n",
      "Epoch 386: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.6021e-04 - accuracy: 1.0000 - val_loss: 1.8617 - val_accuracy: 0.7467\n",
      "Epoch 387/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.5757e-04 - accuracy: 1.0000\n",
      "Epoch 387: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.5832e-04 - accuracy: 1.0000 - val_loss: 1.8617 - val_accuracy: 0.7400\n",
      "Epoch 388/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.5946e-04 - accuracy: 1.0000\n",
      "Epoch 388: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.5854e-04 - accuracy: 1.0000 - val_loss: 1.8718 - val_accuracy: 0.7467\n",
      "Epoch 389/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.5621e-04 - accuracy: 1.0000\n",
      "Epoch 389: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.5573e-04 - accuracy: 1.0000 - val_loss: 1.8635 - val_accuracy: 0.7467\n",
      "Epoch 390/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 1.5834e-04 - accuracy: 1.0000\n",
      "Epoch 390: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.5354e-04 - accuracy: 1.0000 - val_loss: 1.8712 - val_accuracy: 0.7400\n",
      "Epoch 391/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4979e-04 - accuracy: 1.0000\n",
      "Epoch 391: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.5555e-04 - accuracy: 1.0000 - val_loss: 1.8751 - val_accuracy: 0.7467\n",
      "Epoch 392/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4893e-04 - accuracy: 1.0000\n",
      "Epoch 392: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4903e-04 - accuracy: 1.0000 - val_loss: 1.8698 - val_accuracy: 0.7400\n",
      "Epoch 393/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4655e-04 - accuracy: 1.0000\n",
      "Epoch 393: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.5361e-04 - accuracy: 1.0000 - val_loss: 1.8853 - val_accuracy: 0.7400\n",
      "Epoch 394/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4849e-04 - accuracy: 1.0000\n",
      "Epoch 394: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.5322e-04 - accuracy: 1.0000 - val_loss: 1.8671 - val_accuracy: 0.7400\n",
      "Epoch 395/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4902e-04 - accuracy: 1.0000\n",
      "Epoch 395: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.5758e-04 - accuracy: 1.0000 - val_loss: 1.8779 - val_accuracy: 0.7467\n",
      "Epoch 396/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4646e-04 - accuracy: 1.0000\n",
      "Epoch 396: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.4802e-04 - accuracy: 1.0000 - val_loss: 1.8835 - val_accuracy: 0.7467\n",
      "Epoch 397/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 1.5140e-04 - accuracy: 1.0000\n",
      "Epoch 397: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.4522e-04 - accuracy: 1.0000 - val_loss: 1.8782 - val_accuracy: 0.7400\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.4614e-04 - accuracy: 1.0000\n",
      "Epoch 398: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.4614e-04 - accuracy: 1.0000 - val_loss: 1.8852 - val_accuracy: 0.7467\n",
      "Epoch 399/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.3819e-04 - accuracy: 1.0000\n",
      "Epoch 399: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4437e-04 - accuracy: 1.0000 - val_loss: 1.8911 - val_accuracy: 0.7467\n",
      "Epoch 400/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 1.4451e-04 - accuracy: 1.0000\n",
      "Epoch 400: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.4201e-04 - accuracy: 1.0000 - val_loss: 1.8758 - val_accuracy: 0.7400\n",
      "Epoch 401/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4973e-04 - accuracy: 1.0000\n",
      "Epoch 401: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.4137e-04 - accuracy: 1.0000 - val_loss: 1.8931 - val_accuracy: 0.7467\n",
      "Epoch 402/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4066e-04 - accuracy: 1.0000\n",
      "Epoch 402: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4020e-04 - accuracy: 1.0000 - val_loss: 1.8886 - val_accuracy: 0.7400\n",
      "Epoch 403/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4931e-04 - accuracy: 1.0000\n",
      "Epoch 403: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4250e-04 - accuracy: 1.0000 - val_loss: 1.8908 - val_accuracy: 0.7400\n",
      "Epoch 404/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4070e-04 - accuracy: 1.0000\n",
      "Epoch 404: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.3649e-04 - accuracy: 1.0000 - val_loss: 1.8972 - val_accuracy: 0.7400\n",
      "Epoch 405/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.3839e-04 - accuracy: 1.0000\n",
      "Epoch 405: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.3679e-04 - accuracy: 1.0000 - val_loss: 1.8983 - val_accuracy: 0.7400\n",
      "Epoch 406/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4427e-04 - accuracy: 1.0000\n",
      "Epoch 406: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.3412e-04 - accuracy: 1.0000 - val_loss: 1.9072 - val_accuracy: 0.7400\n",
      "Epoch 407/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.3421e-04 - accuracy: 1.0000\n",
      "Epoch 407: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.3294e-04 - accuracy: 1.0000 - val_loss: 1.8977 - val_accuracy: 0.7467\n",
      "Epoch 408/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.2651e-04 - accuracy: 1.0000\n",
      "Epoch 408: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.3228e-04 - accuracy: 1.0000 - val_loss: 1.8981 - val_accuracy: 0.7400\n",
      "Epoch 409/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.2450e-04 - accuracy: 1.0000\n",
      "Epoch 409: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.3203e-04 - accuracy: 1.0000 - val_loss: 1.9029 - val_accuracy: 0.7400\n",
      "Epoch 410/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1663e-04 - accuracy: 1.0000\n",
      "Epoch 410: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.3097e-04 - accuracy: 1.0000 - val_loss: 1.8966 - val_accuracy: 0.7467\n",
      "Epoch 411/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.3558e-04 - accuracy: 1.0000\n",
      "Epoch 411: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.2883e-04 - accuracy: 1.0000 - val_loss: 1.9059 - val_accuracy: 0.7400\n",
      "Epoch 412/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.4106e-04 - accuracy: 1.0000\n",
      "Epoch 412: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.2952e-04 - accuracy: 1.0000 - val_loss: 1.9158 - val_accuracy: 0.7467\n",
      "Epoch 413/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.3653e-04 - accuracy: 1.0000\n",
      "Epoch 413: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.2764e-04 - accuracy: 1.0000 - val_loss: 1.9025 - val_accuracy: 0.7400\n",
      "Epoch 414/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.3767e-04 - accuracy: 1.0000\n",
      "Epoch 414: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.2619e-04 - accuracy: 1.0000 - val_loss: 1.9035 - val_accuracy: 0.7400\n",
      "Epoch 415/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1855e-04 - accuracy: 1.0000\n",
      "Epoch 415: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.2532e-04 - accuracy: 1.0000 - val_loss: 1.9150 - val_accuracy: 0.7400\n",
      "Epoch 416/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.3070e-04 - accuracy: 1.0000\n",
      "Epoch 416: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.2611e-04 - accuracy: 1.0000 - val_loss: 1.9159 - val_accuracy: 0.7400\n",
      "Epoch 417/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.0353e-04 - accuracy: 1.0000\n",
      "Epoch 417: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.2351e-04 - accuracy: 1.0000 - val_loss: 1.9124 - val_accuracy: 0.7400\n",
      "Epoch 418/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1904e-04 - accuracy: 1.0000\n",
      "Epoch 418: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.2173e-04 - accuracy: 1.0000 - val_loss: 1.9152 - val_accuracy: 0.7467\n",
      "Epoch 419/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.2112e-04 - accuracy: 1.0000\n",
      "Epoch 419: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.2163e-04 - accuracy: 1.0000 - val_loss: 1.9161 - val_accuracy: 0.7400\n",
      "Epoch 420/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.2134e-04 - accuracy: 1.0000\n",
      "Epoch 420: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.2012e-04 - accuracy: 1.0000 - val_loss: 1.9265 - val_accuracy: 0.7400\n",
      "Epoch 421/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 1.0630e-04 - accuracy: 1.0000\n",
      "Epoch 421: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.1842e-04 - accuracy: 1.0000 - val_loss: 1.9167 - val_accuracy: 0.7400\n",
      "Epoch 422/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1049e-04 - accuracy: 1.0000\n",
      "Epoch 422: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.1960e-04 - accuracy: 1.0000 - val_loss: 1.9178 - val_accuracy: 0.7400\n",
      "Epoch 423/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1049e-04 - accuracy: 1.0000\n",
      "Epoch 423: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.1823e-04 - accuracy: 1.0000 - val_loss: 1.9405 - val_accuracy: 0.7333\n",
      "Epoch 424/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1399e-04 - accuracy: 1.0000\n",
      "Epoch 424: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.1701e-04 - accuracy: 1.0000 - val_loss: 1.9168 - val_accuracy: 0.7400\n",
      "Epoch 425/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 1.2040e-04 - accuracy: 1.0000\n",
      "Epoch 425: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.1581e-04 - accuracy: 1.0000 - val_loss: 1.9271 - val_accuracy: 0.7400\n",
      "Epoch 426/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.2266e-04 - accuracy: 1.0000\n",
      "Epoch 426: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.1486e-04 - accuracy: 1.0000 - val_loss: 1.9389 - val_accuracy: 0.7333\n",
      "Epoch 427/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.2724e-04 - accuracy: 1.0000\n",
      "Epoch 427: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.1435e-04 - accuracy: 1.0000 - val_loss: 1.9276 - val_accuracy: 0.7400\n",
      "Epoch 428/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1360e-04 - accuracy: 1.0000\n",
      "Epoch 428: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.1308e-04 - accuracy: 1.0000 - val_loss: 1.9279 - val_accuracy: 0.7400\n",
      "Epoch 429/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.8582e-05 - accuracy: 1.0000\n",
      "Epoch 429: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.1329e-04 - accuracy: 1.0000 - val_loss: 1.9340 - val_accuracy: 0.7467\n",
      "Epoch 430/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1721e-04 - accuracy: 1.0000\n",
      "Epoch 430: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.1151e-04 - accuracy: 1.0000 - val_loss: 1.9393 - val_accuracy: 0.7400\n",
      "Epoch 431/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.0800e-04 - accuracy: 1.0000\n",
      "Epoch 431: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.1167e-04 - accuracy: 1.0000 - val_loss: 1.9466 - val_accuracy: 0.7333\n",
      "Epoch 432/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 1.0900e-04 - accuracy: 1.0000\n",
      "Epoch 432: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0856e-04 - accuracy: 1.0000 - val_loss: 1.9318 - val_accuracy: 0.7400\n",
      "Epoch 433/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.0876e-04 - accuracy: 1.0000\n",
      "Epoch 433: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.1092e-04 - accuracy: 1.0000 - val_loss: 1.9401 - val_accuracy: 0.7400\n",
      "Epoch 434/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.8791e-05 - accuracy: 1.0000\n",
      "Epoch 434: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0773e-04 - accuracy: 1.0000 - val_loss: 1.9413 - val_accuracy: 0.7400\n",
      "Epoch 435/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1193e-04 - accuracy: 1.0000\n",
      "Epoch 435: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0784e-04 - accuracy: 1.0000 - val_loss: 1.9436 - val_accuracy: 0.7400\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0728e-04 - accuracy: 1.0000\n",
      "Epoch 436: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0728e-04 - accuracy: 1.0000 - val_loss: 1.9462 - val_accuracy: 0.7400\n",
      "Epoch 437/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.0493e-04 - accuracy: 1.0000\n",
      "Epoch 437: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0574e-04 - accuracy: 1.0000 - val_loss: 1.9533 - val_accuracy: 0.7333\n",
      "Epoch 438/500\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 1.0602e-04 - accuracy: 1.0000\n",
      "Epoch 438: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 1.0451e-04 - accuracy: 1.0000 - val_loss: 1.9479 - val_accuracy: 0.7333\n",
      "Epoch 439/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.6431e-05 - accuracy: 1.0000\n",
      "Epoch 439: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0854e-04 - accuracy: 1.0000 - val_loss: 1.9476 - val_accuracy: 0.7400\n",
      "Epoch 440/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.1485e-04 - accuracy: 1.0000\n",
      "Epoch 440: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0748e-04 - accuracy: 1.0000 - val_loss: 1.9478 - val_accuracy: 0.7467\n",
      "Epoch 441/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.6747e-05 - accuracy: 1.0000\n",
      "Epoch 441: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0493e-04 - accuracy: 1.0000 - val_loss: 1.9514 - val_accuracy: 0.7400\n",
      "Epoch 442/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.9049e-05 - accuracy: 1.0000\n",
      "Epoch 442: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.0195e-04 - accuracy: 1.0000 - val_loss: 1.9471 - val_accuracy: 0.7400\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0181e-04 - accuracy: 1.0000\n",
      "Epoch 443: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.0181e-04 - accuracy: 1.0000 - val_loss: 1.9602 - val_accuracy: 0.7333\n",
      "Epoch 444/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.0739e-04 - accuracy: 1.0000\n",
      "Epoch 444: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0021e-04 - accuracy: 1.0000 - val_loss: 1.9608 - val_accuracy: 0.7333\n",
      "Epoch 445/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.3982e-05 - accuracy: 1.0000\n",
      "Epoch 445: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 9.9009e-05 - accuracy: 1.0000 - val_loss: 1.9582 - val_accuracy: 0.7400\n",
      "Epoch 446/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.6810e-05 - accuracy: 1.0000\n",
      "Epoch 446: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.8670e-05 - accuracy: 1.0000 - val_loss: 1.9576 - val_accuracy: 0.7400\n",
      "Epoch 447/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.7030e-05 - accuracy: 1.0000\n",
      "Epoch 447: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.7904e-05 - accuracy: 1.0000 - val_loss: 1.9692 - val_accuracy: 0.7333\n",
      "Epoch 448/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.0059e-04 - accuracy: 1.0000\n",
      "Epoch 448: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 9.7734e-05 - accuracy: 1.0000 - val_loss: 1.9608 - val_accuracy: 0.7333\n",
      "Epoch 449/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.8871e-05 - accuracy: 1.0000\n",
      "Epoch 449: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.6601e-05 - accuracy: 1.0000 - val_loss: 1.9609 - val_accuracy: 0.7400\n",
      "Epoch 450/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 8.8724e-05 - accuracy: 1.0000\n",
      "Epoch 450: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 9.6272e-05 - accuracy: 1.0000 - val_loss: 1.9735 - val_accuracy: 0.7333\n",
      "Epoch 451/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.1387e-05 - accuracy: 1.0000\n",
      "Epoch 451: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 9.4618e-05 - accuracy: 1.0000 - val_loss: 1.9697 - val_accuracy: 0.7333\n",
      "Epoch 452/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 1.0014e-04 - accuracy: 1.0000\n",
      "Epoch 452: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.5205e-05 - accuracy: 1.0000 - val_loss: 1.9636 - val_accuracy: 0.7400\n",
      "Epoch 453/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.3390e-05 - accuracy: 1.0000\n",
      "Epoch 453: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 9.4290e-05 - accuracy: 1.0000 - val_loss: 1.9790 - val_accuracy: 0.7333\n",
      "Epoch 454/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.4319e-05 - accuracy: 1.0000\n",
      "Epoch 454: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 9.3205e-05 - accuracy: 1.0000 - val_loss: 1.9734 - val_accuracy: 0.7333\n",
      "Epoch 455/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.8510e-05 - accuracy: 1.0000\n",
      "Epoch 455: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.2316e-05 - accuracy: 1.0000 - val_loss: 1.9698 - val_accuracy: 0.7400\n",
      "Epoch 456/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.4195e-05 - accuracy: 1.0000\n",
      "Epoch 456: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 9.1802e-05 - accuracy: 1.0000 - val_loss: 1.9827 - val_accuracy: 0.7333\n",
      "Epoch 457/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.3709e-05 - accuracy: 1.0000\n",
      "Epoch 457: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.1497e-05 - accuracy: 1.0000 - val_loss: 1.9747 - val_accuracy: 0.7333\n",
      "Epoch 458/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.0684e-05 - accuracy: 1.0000\n",
      "Epoch 458: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 9.0815e-05 - accuracy: 1.0000 - val_loss: 1.9765 - val_accuracy: 0.7400\n",
      "Epoch 459/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.9403e-05 - accuracy: 1.0000\n",
      "Epoch 459: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.9831e-05 - accuracy: 1.0000 - val_loss: 1.9876 - val_accuracy: 0.7333\n",
      "Epoch 460/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.2783e-05 - accuracy: 1.0000\n",
      "Epoch 460: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.9163e-05 - accuracy: 1.0000 - val_loss: 1.9859 - val_accuracy: 0.7333\n",
      "Epoch 461/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.4955e-05 - accuracy: 1.0000\n",
      "Epoch 461: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 8.8394e-05 - accuracy: 1.0000 - val_loss: 1.9846 - val_accuracy: 0.7333\n",
      "Epoch 462/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.0231e-05 - accuracy: 1.0000\n",
      "Epoch 462: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.8666e-05 - accuracy: 1.0000 - val_loss: 1.9827 - val_accuracy: 0.7333\n",
      "Epoch 463/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 9.2385e-05 - accuracy: 1.0000\n",
      "Epoch 463: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.8161e-05 - accuracy: 1.0000 - val_loss: 1.9898 - val_accuracy: 0.7333\n",
      "Epoch 464/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.5157e-05 - accuracy: 1.0000\n",
      "Epoch 464: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.8413e-05 - accuracy: 1.0000 - val_loss: 1.9869 - val_accuracy: 0.7333\n",
      "Epoch 465/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.1826e-05 - accuracy: 1.0000\n",
      "Epoch 465: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.6616e-05 - accuracy: 1.0000 - val_loss: 1.9932 - val_accuracy: 0.7333\n",
      "Epoch 466/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.1113e-05 - accuracy: 1.0000\n",
      "Epoch 466: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.8018e-05 - accuracy: 1.0000 - val_loss: 1.9951 - val_accuracy: 0.7333\n",
      "Epoch 467/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.9400e-05 - accuracy: 1.0000\n",
      "Epoch 467: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.6881e-05 - accuracy: 1.0000 - val_loss: 1.9937 - val_accuracy: 0.7400\n",
      "Epoch 468/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.9438e-05 - accuracy: 1.0000\n",
      "Epoch 468: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.4579e-05 - accuracy: 1.0000 - val_loss: 1.9920 - val_accuracy: 0.7333\n",
      "Epoch 469/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.6911e-05 - accuracy: 1.0000\n",
      "Epoch 469: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.4459e-05 - accuracy: 1.0000 - val_loss: 2.0061 - val_accuracy: 0.7333\n",
      "Epoch 470/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.7862e-05 - accuracy: 1.0000\n",
      "Epoch 470: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.3669e-05 - accuracy: 1.0000 - val_loss: 2.0031 - val_accuracy: 0.7333\n",
      "Epoch 471/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.5978e-05 - accuracy: 1.0000\n",
      "Epoch 471: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.3006e-05 - accuracy: 1.0000 - val_loss: 1.9980 - val_accuracy: 0.7333\n",
      "Epoch 472/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.8256e-05 - accuracy: 1.0000\n",
      "Epoch 472: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.1462e-05 - accuracy: 1.0000 - val_loss: 2.0030 - val_accuracy: 0.7333\n",
      "Epoch 473/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.0644e-05 - accuracy: 1.0000\n",
      "Epoch 473: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.0845e-05 - accuracy: 1.0000 - val_loss: 2.0032 - val_accuracy: 0.7333\n",
      "Epoch 474/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.1721e-05 - accuracy: 1.0000\n",
      "Epoch 474: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 8.0962e-05 - accuracy: 1.0000 - val_loss: 2.0065 - val_accuracy: 0.7333\n",
      "Epoch 475/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.4315e-05 - accuracy: 1.0000\n",
      "Epoch 475: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.0303e-05 - accuracy: 1.0000 - val_loss: 2.0122 - val_accuracy: 0.7333\n",
      "Epoch 476/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.2987e-05 - accuracy: 1.0000\n",
      "Epoch 476: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 7.9743e-05 - accuracy: 1.0000 - val_loss: 2.0077 - val_accuracy: 0.7333\n",
      "Epoch 477/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.9754e-05 - accuracy: 1.0000\n",
      "Epoch 477: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.8705e-05 - accuracy: 1.0000 - val_loss: 2.0038 - val_accuracy: 0.7333\n",
      "Epoch 478/500\n",
      "4/7 [================>.............] - ETA: 0s - loss: 6.8745e-05 - accuracy: 1.0000\n",
      "Epoch 478: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 7.8735e-05 - accuracy: 1.0000 - val_loss: 2.0159 - val_accuracy: 0.7333\n",
      "Epoch 479/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 8.4678e-05 - accuracy: 1.0000\n",
      "Epoch 479: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.8088e-05 - accuracy: 1.0000 - val_loss: 2.0192 - val_accuracy: 0.7333\n",
      "Epoch 480/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.4604e-05 - accuracy: 1.0000\n",
      "Epoch 480: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.6838e-05 - accuracy: 1.0000 - val_loss: 2.0072 - val_accuracy: 0.7333\n",
      "Epoch 481/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.4639e-05 - accuracy: 1.0000\n",
      "Epoch 481: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.6288e-05 - accuracy: 1.0000 - val_loss: 2.0169 - val_accuracy: 0.7333\n",
      "Epoch 482/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.6052e-05 - accuracy: 1.0000\n",
      "Epoch 482: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.5910e-05 - accuracy: 1.0000 - val_loss: 2.0244 - val_accuracy: 0.7333\n",
      "Epoch 483/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.6202e-05 - accuracy: 1.0000\n",
      "Epoch 483: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.6400e-05 - accuracy: 1.0000 - val_loss: 2.0179 - val_accuracy: 0.7333\n",
      "Epoch 484/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.1412e-05 - accuracy: 1.0000\n",
      "Epoch 484: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 7.4803e-05 - accuracy: 1.0000 - val_loss: 2.0230 - val_accuracy: 0.7333\n",
      "Epoch 485/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.0849e-05 - accuracy: 1.0000\n",
      "Epoch 485: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.4493e-05 - accuracy: 1.0000 - val_loss: 2.0234 - val_accuracy: 0.7333\n",
      "Epoch 486/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.3621e-05 - accuracy: 1.0000\n",
      "Epoch 486: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.6486e-05 - accuracy: 1.0000 - val_loss: 2.0267 - val_accuracy: 0.7333\n",
      "Epoch 487/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.9139e-05 - accuracy: 1.0000\n",
      "Epoch 487: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.4740e-05 - accuracy: 1.0000 - val_loss: 2.0271 - val_accuracy: 0.7333\n",
      "Epoch 488/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.2787e-05 - accuracy: 1.0000\n",
      "Epoch 488: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.3200e-05 - accuracy: 1.0000 - val_loss: 2.0297 - val_accuracy: 0.7333\n",
      "Epoch 489/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.3682e-05 - accuracy: 1.0000\n",
      "Epoch 489: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 7.2619e-05 - accuracy: 1.0000 - val_loss: 2.0292 - val_accuracy: 0.7333\n",
      "Epoch 490/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.1213e-05 - accuracy: 1.0000\n",
      "Epoch 490: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.1891e-05 - accuracy: 1.0000 - val_loss: 2.0332 - val_accuracy: 0.7333\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 7.2093e-05 - accuracy: 1.0000\n",
      "Epoch 491: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 7.2093e-05 - accuracy: 1.0000 - val_loss: 2.0278 - val_accuracy: 0.7400\n",
      "Epoch 492/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.5356e-05 - accuracy: 1.0000\n",
      "Epoch 492: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 7.2219e-05 - accuracy: 1.0000 - val_loss: 2.0273 - val_accuracy: 0.7333\n",
      "Epoch 493/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.4354e-05 - accuracy: 1.0000\n",
      "Epoch 493: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 7.0459e-05 - accuracy: 1.0000 - val_loss: 2.0369 - val_accuracy: 0.7333\n",
      "Epoch 494/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.7831e-05 - accuracy: 1.0000\n",
      "Epoch 494: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 7.0445e-05 - accuracy: 1.0000 - val_loss: 2.0419 - val_accuracy: 0.7333\n",
      "Epoch 495/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.6055e-05 - accuracy: 1.0000\n",
      "Epoch 495: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 6.9624e-05 - accuracy: 1.0000 - val_loss: 2.0389 - val_accuracy: 0.7333\n",
      "Epoch 496/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.5573e-05 - accuracy: 1.0000\n",
      "Epoch 496: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 7.0095e-05 - accuracy: 1.0000 - val_loss: 2.0357 - val_accuracy: 0.7333\n",
      "Epoch 497/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.0800e-05 - accuracy: 1.0000\n",
      "Epoch 497: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 6.8366e-05 - accuracy: 1.0000 - val_loss: 2.0424 - val_accuracy: 0.7333\n",
      "Epoch 498/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.9861e-05 - accuracy: 1.0000\n",
      "Epoch 498: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 6.8433e-05 - accuracy: 1.0000 - val_loss: 2.0404 - val_accuracy: 0.7333\n",
      "Epoch 499/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 7.1328e-05 - accuracy: 1.0000\n",
      "Epoch 499: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 6.8494e-05 - accuracy: 1.0000 - val_loss: 2.0476 - val_accuracy: 0.7333\n",
      "Epoch 500/500\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 6.9857e-05 - accuracy: 1.0000\n",
      "Epoch 500: val_accuracy did not improve from 0.76000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 6.7688e-05 - accuracy: 1.0000 - val_loss: 2.0505 - val_accuracy: 0.7333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint_filepath = 'FCCN_best_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_filepath, \n",
    "                                   monitor='val_accuracy', \n",
    "                                   save_best_only=True,\n",
    "                                   mode='max',\n",
    "                                   verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(X_train_final, y_train_one_hot, epochs=epochs, batch_size=batches, validation_data=(X_val_final, y_val_one_hot),callbacks=[model_checkpoint])\n",
    "\n",
    "# Plotting training and validation accuracies\n",
    "plt.plot(np.arange(1, epochs + 1), history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(np.arange(1, epochs + 1), history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Epoch-wise Training and Validation Accuracies')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Save the model\n",
    "# model.save('perceptron_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n",
      "Test Loss: 0.8909\n",
      "Test Accuracy: 73.67%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loaded_model = tf.keras.models.load_model('FCCN_best_model.h5')\n",
    "y_pred = loaded_model.predict(X_test_final)\n",
    "\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_true_classes = tf.argmax(y_test_final, axis=1)\n",
    "\n",
    "test_results = loaded_model.evaluate(X_test_final, y_test_final, verbose=0)\n",
    "\n",
    "test_loss = test_results[0]\n",
    "test_accuracy = test_results[1]\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "batches=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CNN=normalize_images(X_train)\n",
    "X_val_CNN=normalize_images(X_val)\n",
    "X_test_CNN=normalize_images(X_t)\n",
    "# print(X_train_CNN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_CNN=one_hot_encoder(y_train)\n",
    "# y_test_CNN=one_hot_encoder(y)\n",
    "y_val_CNN=one_hot_encoder(y_val)\n",
    "y_test_CNN=one_hot_encoder(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 16, 16, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 8, 8, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 100)               51300     \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4506579 (17.19 MB)\n",
      "Trainable params: 4506579 (17.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model1 = models.Sequential()\n",
    "\n",
    "model1.add(layers.Conv2D(64, (3, 3), activation='relu',padding='same', input_shape=(32, 32, 3)))\n",
    "model1.add(layers.Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model1.add(layers.Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "model1.add(layers.Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "model1.add(layers.MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model1.add(layers.Flatten())\n",
    "\n",
    "model1.add(layers.Dense(512, activation='relu'))\n",
    "model1.add(layers.Dense(100, activation='relu'))\n",
    "\n",
    "model1.add(layers.Dense(3, activation='softmax'))  \n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.1113 - accuracy: 0.3556\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60000, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 7s 825ms/step - loss: 1.1113 - accuracy: 0.3556 - val_loss: 1.0560 - val_accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.5756\n",
      "Epoch 2: val_accuracy improved from 0.60000 to 0.68667, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 1.0060 - accuracy: 0.5756 - val_loss: 0.8857 - val_accuracy: 0.6867\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8552 - accuracy: 0.6837\n",
      "Epoch 3: val_accuracy improved from 0.68667 to 0.73333, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 803ms/step - loss: 0.8552 - accuracy: 0.6837 - val_loss: 0.7368 - val_accuracy: 0.7333\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.6852\n",
      "Epoch 4: val_accuracy did not improve from 0.73333\n",
      "7/7 [==============================] - 6s 808ms/step - loss: 0.7405 - accuracy: 0.6852 - val_loss: 0.7693 - val_accuracy: 0.6467\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.7148\n",
      "Epoch 5: val_accuracy improved from 0.73333 to 0.74000, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.6775 - accuracy: 0.7148 - val_loss: 0.6531 - val_accuracy: 0.7400\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.7526\n",
      "Epoch 6: val_accuracy improved from 0.74000 to 0.76667, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 808ms/step - loss: 0.5926 - accuracy: 0.7526 - val_loss: 0.5632 - val_accuracy: 0.7667\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.7874\n",
      "Epoch 7: val_accuracy did not improve from 0.76667\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 0.5221 - accuracy: 0.7874 - val_loss: 0.7441 - val_accuracy: 0.7400\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7748\n",
      "Epoch 8: val_accuracy did not improve from 0.76667\n",
      "7/7 [==============================] - 5s 768ms/step - loss: 0.5660 - accuracy: 0.7748 - val_loss: 0.5588 - val_accuracy: 0.7600\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.8052\n",
      "Epoch 9: val_accuracy improved from 0.76667 to 0.78000, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 798ms/step - loss: 0.5026 - accuracy: 0.8052 - val_loss: 0.5176 - val_accuracy: 0.7800\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8252\n",
      "Epoch 10: val_accuracy did not improve from 0.78000\n",
      "7/7 [==============================] - 6s 781ms/step - loss: 0.4366 - accuracy: 0.8252 - val_loss: 0.5512 - val_accuracy: 0.7733\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8519\n",
      "Epoch 11: val_accuracy improved from 0.78000 to 0.78667, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.3911 - accuracy: 0.8519 - val_loss: 0.5083 - val_accuracy: 0.7867\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8556\n",
      "Epoch 12: val_accuracy did not improve from 0.78667\n",
      "7/7 [==============================] - 5s 778ms/step - loss: 0.3548 - accuracy: 0.8556 - val_loss: 0.5348 - val_accuracy: 0.7667\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.8496\n",
      "Epoch 13: val_accuracy did not improve from 0.78667\n",
      "7/7 [==============================] - 6s 803ms/step - loss: 0.3685 - accuracy: 0.8496 - val_loss: 0.4915 - val_accuracy: 0.7667\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3071 - accuracy: 0.8822\n",
      "Epoch 14: val_accuracy improved from 0.78667 to 0.79333, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 892ms/step - loss: 0.3071 - accuracy: 0.8822 - val_loss: 0.4685 - val_accuracy: 0.7933\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.9000\n",
      "Epoch 15: val_accuracy improved from 0.79333 to 0.80000, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 914ms/step - loss: 0.2557 - accuracy: 0.9000 - val_loss: 0.5310 - val_accuracy: 0.8000\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.9141\n",
      "Epoch 16: val_accuracy improved from 0.80000 to 0.80667, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 805ms/step - loss: 0.2300 - accuracy: 0.9141 - val_loss: 0.4901 - val_accuracy: 0.8067\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9444\n",
      "Epoch 17: val_accuracy did not improve from 0.80667\n",
      "7/7 [==============================] - 6s 798ms/step - loss: 0.1714 - accuracy: 0.9444 - val_loss: 0.4638 - val_accuracy: 0.7933\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9504\n",
      "Epoch 18: val_accuracy improved from 0.80667 to 0.82000, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 840ms/step - loss: 0.1457 - accuracy: 0.9504 - val_loss: 0.5040 - val_accuracy: 0.8200\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9526\n",
      "Epoch 19: val_accuracy did not improve from 0.82000\n",
      "7/7 [==============================] - 6s 793ms/step - loss: 0.1271 - accuracy: 0.9526 - val_loss: 0.5878 - val_accuracy: 0.7933\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9600\n",
      "Epoch 20: val_accuracy did not improve from 0.82000\n",
      "7/7 [==============================] - 6s 794ms/step - loss: 0.1078 - accuracy: 0.9600 - val_loss: 0.6466 - val_accuracy: 0.8133\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9689\n",
      "Epoch 21: val_accuracy did not improve from 0.82000\n",
      "7/7 [==============================] - 5s 782ms/step - loss: 0.0935 - accuracy: 0.9689 - val_loss: 0.5551 - val_accuracy: 0.7867\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9681\n",
      "Epoch 22: val_accuracy improved from 0.82000 to 0.82667, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 817ms/step - loss: 0.0842 - accuracy: 0.9681 - val_loss: 0.5128 - val_accuracy: 0.8267\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9726\n",
      "Epoch 23: val_accuracy did not improve from 0.82667\n",
      "7/7 [==============================] - 6s 806ms/step - loss: 0.0704 - accuracy: 0.9726 - val_loss: 0.5878 - val_accuracy: 0.8000\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9770\n",
      "Epoch 24: val_accuracy did not improve from 0.82667\n",
      "7/7 [==============================] - 6s 792ms/step - loss: 0.0655 - accuracy: 0.9770 - val_loss: 0.4985 - val_accuracy: 0.8200\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9911\n",
      "Epoch 25: val_accuracy improved from 0.82667 to 0.84667, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 846ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.5002 - val_accuracy: 0.8467\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9911\n",
      "Epoch 26: val_accuracy improved from 0.84667 to 0.86000, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 816ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.5300 - val_accuracy: 0.8600\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9970\n",
      "Epoch 27: val_accuracy did not improve from 0.86000\n",
      "7/7 [==============================] - 6s 796ms/step - loss: 0.0197 - accuracy: 0.9970 - val_loss: 0.6284 - val_accuracy: 0.8600\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9978\n",
      "Epoch 28: val_accuracy did not improve from 0.86000\n",
      "7/7 [==============================] - 6s 787ms/step - loss: 0.0114 - accuracy: 0.9978 - val_loss: 0.7387 - val_accuracy: 0.8000\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9985\n",
      "Epoch 29: val_accuracy improved from 0.86000 to 0.87333, saving model to CNN_best_model.h5\n",
      "7/7 [==============================] - 6s 831ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.6578 - val_accuracy: 0.8733\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9993\n",
      "Epoch 30: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 810ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.7181 - val_accuracy: 0.8400\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9993\n",
      "Epoch 31: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 801ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.7938 - val_accuracy: 0.8133\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 32: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.8400\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 33: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 790ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8280 - val_accuracy: 0.8267\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 34: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7864 - val_accuracy: 0.8267\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 35: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 794ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8153 - val_accuracy: 0.8467\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 9.1715e-04 - accuracy: 1.0000\n",
      "Epoch 36: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 793ms/step - loss: 9.1715e-04 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.8400\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 7.3337e-04 - accuracy: 1.0000\n",
      "Epoch 37: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 795ms/step - loss: 7.3337e-04 - accuracy: 1.0000 - val_loss: 0.8580 - val_accuracy: 0.8400\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 4.9948e-04 - accuracy: 1.0000\n",
      "Epoch 38: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 796ms/step - loss: 4.9948e-04 - accuracy: 1.0000 - val_loss: 0.8774 - val_accuracy: 0.8400\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 5.3066e-04 - accuracy: 1.0000\n",
      "Epoch 39: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 5.3066e-04 - accuracy: 1.0000 - val_loss: 0.8778 - val_accuracy: 0.8400\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 4.1240e-04 - accuracy: 1.0000\n",
      "Epoch 40: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 825ms/step - loss: 4.1240e-04 - accuracy: 1.0000 - val_loss: 0.8835 - val_accuracy: 0.8333\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 3.7913e-04 - accuracy: 1.0000\n",
      "Epoch 41: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 822ms/step - loss: 3.7913e-04 - accuracy: 1.0000 - val_loss: 0.9035 - val_accuracy: 0.8400\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 3.4305e-04 - accuracy: 1.0000\n",
      "Epoch 42: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 798ms/step - loss: 3.4305e-04 - accuracy: 1.0000 - val_loss: 0.9109 - val_accuracy: 0.8333\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 3.0766e-04 - accuracy: 1.0000\n",
      "Epoch 43: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 798ms/step - loss: 3.0766e-04 - accuracy: 1.0000 - val_loss: 0.9112 - val_accuracy: 0.8333\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.8270e-04 - accuracy: 1.0000\n",
      "Epoch 44: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 2.8270e-04 - accuracy: 1.0000 - val_loss: 0.9170 - val_accuracy: 0.8333\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.5983e-04 - accuracy: 1.0000\n",
      "Epoch 45: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 794ms/step - loss: 2.5983e-04 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.8333\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.4702e-04 - accuracy: 1.0000\n",
      "Epoch 46: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 811ms/step - loss: 2.4702e-04 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 0.8333\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.2277e-04 - accuracy: 1.0000\n",
      "Epoch 47: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 817ms/step - loss: 2.2277e-04 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.8333\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.0977e-04 - accuracy: 1.0000\n",
      "Epoch 48: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 807ms/step - loss: 2.0977e-04 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.8333\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.9652e-04 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 805ms/step - loss: 1.9652e-04 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.8333\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.8750e-04 - accuracy: 1.0000\n",
      "Epoch 50: val_accuracy did not improve from 0.87333\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 1.8750e-04 - accuracy: 1.0000 - val_loss: 0.9541 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"CNN_best_model.h5\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "history = model1.fit(X_train_CNN, y_train_CNN, epochs=epochs,batch_size=batches, validation_data=(X_val_CNN, y_val_CNN), callbacks=[checkpoint])\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Epoch-wise Training and Validation Accuracies')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 35ms/step\n",
      "Test Loss: 0.8425\n",
      "Test Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loaded_model_CNN = tf.keras.models.load_model('CNN_best_model.h5')\n",
    "y_pred_CNN = loaded_model_CNN.predict(X_test_CNN)\n",
    "\n",
    "y_pred_CNN_classes = tf.argmax(y_pred_CNN, axis=1)\n",
    "y_true_classes = tf.argmax(y_test_CNN, axis=1)\n",
    "\n",
    "test_results_CNN = loaded_model_CNN.evaluate(X_test_CNN, y_test_CNN, verbose=0)\n",
    "\n",
    "test_loss = test_results_CNN[0]\n",
    "test_accuracy_CNN = test_results_CNN[1]\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy_CNN * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300,), dtype=int64, numpy=\n",
       "array([0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 2, 1, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2,\n",
       "       2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_classes\n",
    "y_pred_CNN_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm=confusion_matrix(y_true_classes,y_pred_CNN_classes)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = [\"Aeroplane\", \"Car\",\"Bird\"]  \n",
    "tick_marks = np.arange(len(classes))\n",
    "\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
